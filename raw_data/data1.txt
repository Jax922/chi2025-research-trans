{
  "Target Definition": {
    "Target User Group": "Social media users",
    "Tasks": "Assessing the validity of visual content on social media",
    "Application scenarios": "Evaluating media credibility in social media feeds"
  },
  "Contributions": [
    {
      "Innovation type": "System",
      "Supporting knowledge": "C2PA standard",
      "Function": "Help users assess the credibility of visual content by providing provenance information",
      "Embedded knowledge": {
        "Architecture or framework": "1. Provenance details panel displaying a chain of provenance information. 2. Provenance indicator with different states (normal, incomplete, invalid).",
        "Tool or tool kits": "1. Provenance-enabled social media prototype. 2. Analytics tracking for user interactions."
      },
      "Implementation": "Provenance information display--C2PA standard; User interface--Svelte; Analytics tracking--Custom built"
    },
    {
      "Innovation type": "Interaction techniques",
      "Supporting knowledge": "C2PA UX guidelines",
      "Function": "Enable users to interact with provenance information to make informed credibility judgments",
      "Embedded knowledge": {
        "Input or control techniques": "1. Clicking on provenance indicator to open provenance details panel. 2. Interactive provenance details panel displaying media journey.",
        "Output or feedback methods": "1. Color-coded provenance indicators (normal, incomplete, invalid). 2. Provenance details panel with manifests and content gallery."
      },
      "Implementation": "Provenance interaction--Web app; Provenance display--C2PA standard"
    }
  ],
  "Results": {
    "Performance": "Provenance information significantly affected credibility perception, with trust and perceived accuracy generally decreasing for deceptive media and increasing for authentic media.",
    "User feedback": "Participants found the provenance UIs generally understandable, but suggested improvements for better explanations, interactivity, visibility, and iconography/terminology."
  },
  "Second Extraction": {
    "Innovations": [
      {
        "Previous studies": "Limited to algorithmic or crowdsourced fact-checking methods.",
        "This study": "Introduced provenance-enabled systems with cryptographically signed provenance information to help users assess media credibility."
      },
      {
        "Previous studies": "Focused on static credibility indicators without user interaction.",
        "This study": "Implemented interactive provenance indicators and details panels to provide users with on-demand provenance information."
      }
    ],
    "Quadruple": [
      {
        "Innovation": "Introduced provenance-enabled systems with cryptographically signed provenance information to help users assess media credibility.",
        "Result": "Provenance information significantly affected credibility perception, with trust and perceived accuracy generally decreasing for deceptive media and increasing for authentic media."
      },
      {
        "Innovation": "Implemented interactive provenance indicators and details panels to provide users with on-demand provenance information.",
        "Result": "Participants found the provenance UIs generally understandable, but suggested improvements for better explanations, interactivity, visibility, and iconography/terminology."
      }
    ]
  }
}

{
    "Target Definition": {
        "Target User Group": "General public under time pressure",
        "Tasks": "Human decision-making behavior and task performance under time pressure",
        "Application scenarios": "High-stakes or time-sensitive tasks such as financial trading or medical diagnosis"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Human-AI interaction and decision support tools",
            "Function": "Assist human decision-making under time pressure",
            "Embedded knowledge": {
                "Architecture or framework": [
                    "1. Studied the effects of initial observation time and final decision time on AI-assisted decision-making.",
                    "2. Investigated how task nature influences the impact of time pressure on human-AI collaboration."
                ],
                "Tool or tool kits": [
                    "1. Custom web application using React and Flask frameworks.",
                    "2. Deployed via Heroku for the study."
                ]
            },
            "Implementation": "User study platform--React & Flask; Deployment--Heroku"
        }
    ],
    "Results": {
        "Performance": "Participants were more likely to follow AI suggestions with longer decision time. Error improvement was higher under insufficient observation time. Task nature influenced the impact of time pressure.",
        "User feedback": "Participants reported higher perceived trust and usefulness of AI under insufficient observation time for spatial reasoning tasks. Sufficient decision time led to higher perceived trust and usefulness in count estimation tasks."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Focused on single-phase time pressure effects on decision-making.",
                "This study": "Explored multi-phase time pressure effects on human-AI collaboration, considering both initial observation time and final decision time."
            },
            {
                "Previous studies": "Did not account for task nature in human-AI interaction under time pressure.",
                "This study": "Investigated how the nature of tasks (spatial reasoning vs. count estimation) influences the effects of time pressure on human-AI collaboration."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Explored multi-phase time pressure effects on human-AI collaboration, considering both initial observation time and final decision time.",
                "Result": "Participants were more likely to follow AI suggestions with longer decision time. Error improvement was higher under insufficient observation time."
            },
            {
                "Innovation": "Investigated how the nature of tasks (spatial reasoning vs. count estimation) influences the effects of time pressure on human-AI collaboration.",
                "Result": "Task nature influenced the impact of time pressure. Participants reported higher perceived trust and usefulness of AI under insufficient observation time for spatial reasoning tasks. Sufficient decision time led to higher perceived trust and usefulness in count estimation tasks."
            }
        ]
    }
}

{
    "Target Definition": {
        "Target User Group": "Groups of people making judgments",
        "Tasks": "Reducing uncertainty in group judgments through targeted interventions",
        "Application Scenarios": "Crowdsourcing tasks such as rating word pair similarity and toxicity of online comments"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Crowdsourcing; annotation; ambiguity; calibration",
            "Function": "Reduce uncertainty in group judgments by targeting ambiguity and disagreement",
            "Embedded knowledge": {
                "Architecture or framework": "1. Judgment Sieve workflow: separates sources of uncertainty and applies targeted interventions. 2. Measurement of ambiguity and disagreement for each instance.",
                "Tool or tool kits": "1. Annotation application for range-based scalar ratings. 2. Deliberation application for synchronous discussions."
            },
            "Implementation": "Annotation application--Amazon Mechanical Turk; Deliberation application--Python-based backend"
        }
    ],
    "Results": {
        "Performance": "Targeted interventions reduced uncertainty for the most uncertain cases. Ambiguity reduction of 21.4% and 25.7%, and disagreement reduction of 22.2% and 11.2% for word pair similarity and toxicity tasks respectively.",
        "User feedback": "Participants found the interventions effective in reducing uncertainty, with context improving clarity and deliberation helping resolve disagreements. However, broad application of interventions increased uncertainty in some cases."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Uniform approaches to reduce uncertainty in group judgments.",
                "This study": "Introduced Judgment Sieve, a workflow that targets specific sources of uncertainty (ambiguity and disagreement) with tailored interventions."
            },
            {
                "Previous studies": "Limited methods to measure and address different sources of uncertainty.",
                "This study": "Developed metrics to separately quantify ambiguity and disagreement, allowing for targeted interventions."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Introduced Judgment Sieve, a workflow that targets specific sources of uncertainty (ambiguity and disagreement) with tailored interventions.",
                "Result": "Targeted interventions reduced uncertainty for the most uncertain cases. Ambiguity reduction of 21.4% and 25.7%, and disagreement reduction of 22.2% and 11.2% for word pair similarity and toxicity tasks respectively."
            },
            {
                "Innovation": "Developed metrics to separately quantify ambiguity and disagreement, allowing for targeted interventions.",
                "Result": "Participants found the interventions effective in reducing uncertainty, with context improving clarity and deliberation helping resolve disagreements. However, broad application of interventions increased uncertainty in some cases."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Members of ad-hoc teams in organizational settings",
        "Tasks": "Understanding teammate preferences, tendencies, and attitudes to improve team functioning and efficiency",
        "Application scenarios": "Ad-hoc team formation in organizations for specific tasks"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Team mental models (TMMs), Big Five Personality assessment, Conflict Management Styles assessment",
            "Function": "Promote teammate understanding through selective sharing of interpersonal recommendations",
            "Embedded knowledge": {
                "Architecture or framework": "1. Teammate information-sharing recommender system 2. Personalized recommendations based on personality and conflict management data",
                "Tool or tool kits": "1. Research platform for assessments and recommendations 2. Algorithm for ranking recommendations"
            },
            "Implementation": "Personality and conflict management assessment--Big Five Personality assessment & Rahim & Bonoma’s Conflict Management Styles assessment; Recommendation generation--Custom algorithm; Research platform--Python (Django), Bootstrap, JavaScript"
        }
    ],
    "Results": {
        "Performance": "Identified recommendations resulted in significantly higher team satisfaction and cohesion compared to anonymized recommendations. Team satisfaction and cohesion were significantly higher at the start and midpoint of the project for identified recommendations.",
        "User feedback": "Participants appreciated improved awareness and preparedness, and the ability to interact differently based on improved understanding. However, polar views existed regarding privacy concerns, with some participants finding certain traits sensitive and others seeing no issue with sharing."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Prior research has empirically investigated using technology to share teammate skill information and suggested using technology to share personality information.",
                "This study": "Provides empirical evidence that sharing identified teammate information (i.e., personality and conflict management) can promote positive team outcomes on unfamiliar teams."
            },
            {
                "Previous studies": "Prior research on GRS has investigated how presentation features such as anonymity and explanations influence system perceptions.",
                "This study": "Finds no evidence that anonymized recommendations decrease privacy concerns or that explanations increase trust or satisfaction for an information-sharing recommender system."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Provides empirical evidence that sharing identified teammate information (i.e., personality and conflict management) can promote positive team outcomes on unfamiliar teams.",
                "Result": "Identified recommendations resulted in significantly higher team satisfaction and cohesion compared to anonymized recommendations."
            },
            {
                "Innovation": "Finds no evidence that anonymized recommendations decrease privacy concerns or that explanations increase trust or satisfaction for an information-sharing recommender system.",
                "Result": "Participants had polar views regarding privacy concerns, with some finding certain traits sensitive and others seeing no issue with sharing."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Former conspiracy theory believers",
        "Tasks": "Understanding engagement, disengagement, and recovery from conspiracy theories online",
        "Application scenarios": "Online communities and platforms supporting recovery from conspiracy theory beliefs"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Cognitive dissonance theory, Role exit theory, Defection model",
            "Function": "Understanding how online and offline factors shape engagement, tenure, and disengagement in conspiracy theorizing",
            "Embedded knowledge": {
                "Architecture or framework": "1. Theoretical models of group exits such as cognitive dissonance and role exit. 2. Empirical analysis of online and offline factors influencing conspiracy theory belief evolution.",
                "Tool or tool kits": "None"
            },
            "Implementation": "In-depth interviews--15 former conspiracy theory believers; Data analysis--Iterative thematic analysis"
        }
    ],
    "Results": {
        "Performance": "The study successfully identified various factors influencing engagement, disengagement, and recovery from conspiracy theories. It highlighted the role of online platforms, social interactions, and offline events in shaping conspiracy theory beliefs.",
        "User feedback": "Participants reported negative impacts on mental health and social connections due to conspiracy theory engagement. They found online recovery communities helpful for support and empathy but faced challenges like online harassment and lack of safe spaces."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Focused on theoretical models of conspiracy belief adoption isolated from social media influence.",
                "This study": "Bridged the gap between theoretical and empirical research by considering online and offline factors influencing conspiracy theory engagement and disengagement."
            },
            {
                "Previous studies": "Limited understanding of the role of online recovery communities.",
                "This study": "Highlighted the importance of online recovery communities in providing support and empathy to former conspiracy theory believers."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Bridged the gap between theoretical and empirical research by considering online and offline factors influencing conspiracy theory engagement and disengagement.",
                "Result": "The study successfully identified various factors influencing engagement, disengagement, and recovery from conspiracy theories. It highlighted the role of online platforms, social interactions, and offline events in shaping conspiracy theory beliefs."
            },
            {
                "Innovation": "Highlighted the importance of online recovery communities in providing support and empathy to former conspiracy theory believers.",
                "Result": "Participants reported negative impacts on mental health and social connections due to conspiracy theory engagement. They found online recovery communities helpful for support and empathy but faced challenges like online harassment and lack of safe spaces."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Active social media users",
        "Tasks": "Configuring personal content moderation settings",
        "Application scenarios": "Moderating content on social media platforms"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Human-centered computing; Empirical studies in collaborative and social computing",
            "Function": "Investigate user perspectives on personal content moderation tools",
            "Embedded knowledge": {
                "Architecture or framework": [
                    "1. Simulated personal moderation interfaces including word filters, sliders for toxicity levels, and boolean toxicity toggles.",
                    "2. A web application that simulates a social media feed of content along with a series of interactive controls."
                ],
                "Tool or tool kits": [
                    "1. A web application with four types of controls based on personal moderation tools.",
                    "2. Simulated personal moderation interfaces including word filters, sliders for toxicity levels, and boolean toxicity toggles."
                ]
            },
            "Implementation": "Web application--Simulated social media feed; Control interfaces--Word filter, toxicity toggle, intensity slider, proportion slider"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Human-centered computing; Empirical studies in collaborative and social computing",
            "Function": "Enable users to configure personal moderation settings",
            "Embedded knowledge": {
                "Input or control techniques": [
                    "1. Word filters to exclude comments containing specific keywords.",
                    "2. Intensity sliders to remove progressively more toxic comments.",
                    "3. Proportion sliders to remove a proportion of toxic comments."
                ],
                "Output or feedback methods": [
                    "1. Displaying example comments to help users understand the effect of different moderation settings.",
                    "2. Showing changes in the simulated feed in response to settings adjustments."
                ]
            },
            "Implementation": "Web application--Simulated social media feed; Control interfaces--Word filter, toxicity toggle, intensity slider, proportion slider"
        }
    ],
    "Results": {
        "Performance": "Participants found the tools useful for configuring personal moderation settings but desired clearer definitions and better context awareness. They appreciated the ability to fine-tune settings but found the labor involved in configuration to be a potential barrier.",
        "User feedback": "Participants expressed a need for more transparency and clarity in the definitions of moderation categories. They also desired more context-aware tools and better feedback mechanisms. The use of examples was appreciated for understanding and controlling moderation settings."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Limited control over personal content moderation, often relying on platform-wide settings.",
                "This study": "Developed a web application with simulated personal moderation interfaces, allowing users to configure settings using word filters, sliders for toxicity levels, and boolean toxicity toggles."
            },
            {
                "Previous studies": "Lack of transparency and clarity in moderation tools.",
                "This study": "Provided example comments and interactive controls to help users understand and configure personal moderation settings."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Developed a web application with simulated personal moderation interfaces, allowing users to configure settings using word filters, sliders for toxicity levels, and boolean toxicity toggles.",
                "Result": "Participants found the tools useful for configuring personal moderation settings but desired clearer definitions and better context awareness. They appreciated the ability to fine-tune settings but found the labor involved in configuration to be a potential barrier."
            },
            {
                "Innovation": "Provided example comments and interactive controls to help users understand and configure personal moderation settings.",
                "Result": "Participants expressed a need for more transparency and clarity in the definitions of moderation categories. They also desired more context-aware tools and better feedback mechanisms. The use of examples was appreciated for understanding and controlling moderation settings."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Parents and community leaders in low-resource South African communities",
        "Tasks": "Engage with rural and urban parents and community leaders to better understand their challenges and priorities for digital maternal and child health",
        "Application Scenarios": "Community-centered workshops and co-design sessions to identify and address digital maternal and child health priorities"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Community-based co-design (CBCD) methodology",
            "Function": "Identify and address community-based digital maternal and child health priorities",
            "Embedded knowledge": {
                "Architecture or framework": "1. Community-based co-design framework for engaging underserved communities in low-resource settings. 2. Parent-centered workshops to co-design digital initiatives.",
                "Tool or tool kits": "1. Challenge and ideation design cards to facilitate understanding and brainstorming. 2. Use of intermediaries to bridge cultural and language gaps."
            },
            "Implementation": "Workshops--Community halls; Design cards--Illustrations and translations; Intermediaries--Local researchers and NGO members"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Participatory methods and value sensitive design (VSD)",
            "Function": "Facilitate community engagement and co-design of digital maternal and child health solutions",
            "Embedded knowledge": {
                "Input or control techniques": "1. Use of design cards to initiate conversations and establish shared understanding. 2. Inclusion of intermediaries to facilitate language translation and cultural familiarity.",
                "Output or feedback methods": "1. Community radio for sharing MCH information. 2. WhatsApp groups for continuous support and engagement."
            },
            "Implementation": "Community engagement--Workshops; Communication--Community radio, WhatsApp groups"
        }
    ],
    "Results": {
        "Performance": "The study successfully identified the top three maternal and child health priorities: parental well-being, building parenting skills in early life, and accessible and affordable health information. The co-design workshops facilitated the creation of contextually-situated solutions that incorporated community spaces and digital tools.",
        "User feedback": "Participants expressed that the workshops were therapeutic and appreciated the opportunity to share their experiences and co-create solutions. They valued the inclusion of community leaders and the use of design cards to facilitate understanding and engagement."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Top-down design approaches without community involvement.",
                "This study": "Community-based co-design framework involving parents and community leaders in low-resource settings."
            },
            {
                "Previous studies": "Limited use of participatory methods and value sensitive design in MCH.",
                "This study": "Use of participatory methods and value sensitive design to facilitate community engagement and co-design of digital MCH solutions."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Community-based co-design framework involving parents and community leaders in low-resource settings.",
                "Result": "Successfully identified community MCH priorities and co-created contextually-situated solutions."
            },
            {
                "Innovation": "Use of participatory methods and value sensitive design to facilitate community engagement and co-design of digital MCH solutions.",
                "Result": "Facilitated understanding and engagement through design cards and intermediaries, leading to the creation of practical and accepted solutions."
            }
        ]
    }
}

{
    "Target Definition": {
        "Target User Group": "South-Asian immigrant grandparents and grandchildren",
        "Tasks": "Collaborative digital crafting and storytelling",
        "Application Scenarios": "Intergenerational and cross-cultural collaboration within immigrant families"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Participatory Design, Contextual Inquiry, Trialogical approach",
            "Function": "Facilitate culture sharing and social connection through digital crafting and storytelling",
            "Embedded knowledge": {
                "Architecture or framework": "1. StoryTapestry app integrating storytelling and digital crafting; 2. Culturally reflective design with South-Asian themed images",
                "Tool or tool kits": "1. StoryTapestry app; 2. Image bank with culturally relevant images"
            },
            "Implementation": "Web-based application--StoryTapestry; Image bank--Culturally relevant images"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Ticket-to-talk concept, Creativity support tools",
            "Function": "Encourage collaborative digital crafting and storytelling",
            "Embedded knowledge": {
                "Input or control techniques": "1. Drag-and-drop image manipulation; 2. Flexible design for image manipulation (size, opacity, rotation, mirroring)",
                "Output or feedback methods": "1. Visual artifacts creation; 2. Audio recording of storytelling"
            },
            "Implementation": "Crafting--Web-based platform; Storytelling--Audio recording"
        },
        {
            "Innovation type": "Design",
            "Supporting knowledge": "Culturally reflective design, Participatory Design",
            "Function": "Create a culturally reflective and engaging digital crafting experience",
            "Embedded knowledge": {
                "Prototype, script or models": "1. StoryTapestry app prototype; 2. Culturally reflective image sets",
                "Material or crafts": "1. South-Asian themed images; 2. Digital visual artifacts"
            },
            "Implementation": "Cultural inspiration--South-Asian art traditions; Image sets--South-Asian and Canadian themes"
        }
    ],
    "Results": {
        "Performance": "The study successfully facilitated collaborative digital crafting and storytelling, fostering positive social connections and culture sharing between South-Asian immigrant grandparents and grandchildren. The thematic analysis revealed that the process encouraged crossing language and culture barriers, knowledge sharing, and creativity.",
        "User feedback": "Participants reported positive emotional responses, enjoyment, and pride in the collaborative process. Grandparents appreciated the opportunity to share cultural knowledge, while grandchildren valued the creative aspects of the activity. Some grandparents experienced moments of disengagement, suggesting the need for additional system support."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Physical crafting as a tool for social connection and culture preservation",
                "This study": "Digital crafting in a culturally reflective app to facilitate intergenerational and cross-cultural collaboration"
            },
            {
                "Previous studies": "Traditional storytelling tools relying on existing artifacts like photographs",
                "This study": "Use of culturally relevant illustrations to prompt reminiscence and culture sharing"
            },
            {
                "Previous studies": "Fixed roles in family storytelling interactions",
                "This study": "Flexible roles allowing bidirectional learning and leadership between grandparents and grandchildren"
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Digital crafting in a culturally reflective app to facilitate intergenerational and cross-cultural collaboration",
                "Result": "The study successfully facilitated collaborative digital crafting and storytelling, fostering positive social connections and culture sharing between South-Asian immigrant grandparents and grandchildren."
            },
            {
                "Innovation": "Use of culturally relevant illustrations to prompt reminiscence and culture sharing",
                "Result": "Participants reported positive emotional responses, enjoyment, and pride in the collaborative process. Grandparents appreciated the opportunity to share cultural knowledge, while grandchildren valued the creative aspects of the activity."
            },
            {
                "Innovation": "Flexible roles allowing bidirectional learning and leadership between grandparents and grandchildren",
                "Result": "Some grandparents experienced moments of disengagement, suggesting the need for additional system support."
            }
        ]
    }
}

{
    "Target Definition": {
        "Target User Group": "Researchers and practitioners in the field of crowdsourcing and human-computer interaction",
        "Tasks": "Crowdsourcing subjective annotations using pairwise comparisons",
        "Application scenarios": "Improving the accuracy and fairness of crowdsourced labelling tasks"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Crowdsourcing framework, Elo rating system",
            "Function": "Reduce measurement variability and bias in crowdsourced labelling",
            "Embedded knowledge": {
                "Architecture or framework": "1. Theoretical framework for understanding how random error and measurement bias enter into crowdsourced annotations of subjective constructs. 2. Pipeline combining pairwise comparison labelling with Elo scoring.",
                "Tool or tool kits": "1. Open-source Python package implementing the Elo system."
            },
            "Implementation": "Agent-based model--Python; Elo system--Python package"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Crowdsourcing framework, Elo rating system",
            "Function": "Reduce bias and error in subjective annotations",
            "Embedded knowledge": {
                "Input or control techniques": "1. Pairwise comparison labelling tasks. 2. Elo scoring system to aggregate comparison results.",
                "Output or feedback methods": "1. Continuous distribution of scores for subjective constructs."
            },
            "Implementation": "Crowdsourcing platform--Amazon Mechanical Turk; Elo rating system--Python package"
        }
    ],
    "Results": {
        "Performance": "The comparison method produced higher F1 scores under most conditions with task subjectivity. It also showed that the number of required random comparisons for the same classification accuracy scales log-linearly O(NlogN) with the number of labelled items.",
        "User feedback": "The comparison method was found to be less susceptible to inflating bias and more resilient towards spam compared to the majority-vote method."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Majority-vote method for crowdsourced labelling",
                "This study": "Proposed a pipeline combining pairwise comparison labelling with Elo scoring to reduce measurement variability and bias."
            },
            {
                "Previous studies": "Traditional item-wise labelling tasks",
                "This study": "Introduced pairwise comparison labelling tasks and an Elo scoring system to aggregate comparison results."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Proposed a pipeline combining pairwise comparison labelling with Elo scoring to reduce measurement variability and bias.",
                "Result": "The comparison method produced higher F1 scores under most conditions with task subjectivity and showed that the number of required random comparisons for the same classification accuracy scales log-linearly O(NlogN) with the number of labelled items."
            },
            {
                "Innovation": "Introduced pairwise comparison labelling tasks and an Elo scoring system to aggregate comparison results.",
                "Result": "The comparison method was found to be less susceptible to inflating bias and more resilient towards spam compared to the majority-vote method."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Software development teams",
        "Tasks": "Balancing individual productivity and team productivity",
        "Application Scenarios": "Hybrid development teams working on shared tasks with specific goals"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Reflection strategies, team cohesion theories",
            "Function": "Cultivate a team-oriented mindset about productivity",
            "Embedded knowledge": {
                "Architecture or framework": "1. Technology probe with a team nudge 2. Hourly self-reports and daily diaries for data collection and reflection",
                "Tool or tool kits": "1. Smartwatch application for hourly self-reports 2. Web application for daily diaries"
            },
            "Implementation": "Hourly self-reports--Smartwatch (Wear OS, watchOS); Daily diaries--Web application"
        }
    ],
    "Results": {
        "Performance": "The team nudge increased participants’ productivity ratings by 1.7% in daily diaries and 2.3% in hourly self-reports. It also led to participants spending more time on their own tasks, with a 3.5% increase in daily surveys and a 2.5% increase in hourly surveys.",
        "User feedback": "Participants reported varied feedback on the team nudge, with 48.6% stating it did not change their perspective significantly, while 32.4% mentioned positive effects such as increased team awareness and improved team interaction. Reflection on work and productivity was generally perceived positively, increasing awareness and optimizing work habits."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Previous studies focused on individual productivity or team productivity separately.",
                "This study": "This study explored the tensions between individual and team productivity, using a technology probe with a team nudge to foster reflection and increase team awareness."
            },
            {
                "Previous studies": "Previous studies did not extensively use minimal interventions like a single reflective question to influence productivity mindsets.",
                "This study": "This study used a minimal team nudge (a single question) to prompt reflection on team contributions to productivity, showing that even small interventions can have significant impacts."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Explored the tensions between individual and team productivity using a technology probe with a team nudge.",
                "Result": "Increased participants’ productivity ratings and team awareness, led to participants spending more time on their own tasks."
            },
            {
                "Innovation": "Used a minimal team nudge (a single question) to prompt reflection on team contributions to productivity.",
                "Result": "Participants reported varied feedback, with some noting increased team awareness and improved team interaction, while others found it fostered reflection and awareness."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Academic researchers using cloud computing resources",
        "Tasks": "User experience on a testbed for cloud computing research, CloudLab",
        "Application Scenarios": "Coordination of time and resources among academic researchers using CloudLab"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "CSCW literature on time management and coordination",
            "Function": "Improve user experience and resource sharing on CloudLab",
            "Embedded knowledge": {
                "Architecture or framework": "1. Visualization of resource availability to support planning and coordination. 2. Mechanisms for reservation and extension of computational resources.",
                "Tool or tool kits": "1. Resource availability graphs. 2. Load average graphs and table views of ongoing experiments."
            },
            "Implementation": "Visualization of resource availability--Graphs and tables on CloudLab platform"
        }
    ],
    "Results": {
        "Performance": "The study found that CloudLab users strategically coordinated their time on the platform, often involving altruistic behaviors where users shared time on CloudLab allocated for personal use. This coordination helped in reducing conflicts over resources and balancing the use of CloudLab over time.",
        "User feedback": "Users found the resource availability graphs and other visualizations useful for planning their experiments and coordinating with other users. However, there were frustrations with the inability to see future reservations and the need for more accurate predictions of resource availability."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Prior studies focused on individual resource management and coordination in scientific software.",
                "This study": "Introduced visualizations to raise awareness of resource availability and academic deadlines, fostering altruistic behaviors and better coordination among users."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Visualization of resource availability to support planning and coordination",
                "Result": "Users found these visualizations useful for planning their experiments and coordinating with others, leading to reduced conflicts over resources."
            },
            {
                "Innovation": "Mechanisms for reservation and extension of computational resources",
                "Result": "Users strategically coordinated their time on the platform, often involving altruistic behaviors where users shared time on CloudLab allocated for personal use."
            }
        ]
    }
}

{
    "Target Definition": {
        "Target User Group": "CNN engineers",
        "Tasks": "Diagnosing and revising CNN’s vulnerability using local explanations",
        "Application scenarios": "Building and improving CNN models for various classification tasks"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Explanation-guided Learning framework",
            "Function": "Diagnose and revise CNN model vulnerabilities using local explanations",
            "Embedded knowledge": {
                "Architecture or framework": "1. Interactive system for CNN vulnerability diagnosis and revision 2. Reasonability Matrix for evaluating model performance",
                "Tool or tool kits": "1. DeepFuse for interactive CNN steering 2. Grad-CAM for generating local explanations"
            },
            "Implementation": "Model upload--PyTorch; Local explanation generation--Grad-CAM; Object detection--Mask R-CNN; Fine-tuning--RES framework"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Explanation-guided Learning framework",
            "Function": "Help CNN engineers identify and correct unreasonable model attention",
            "Embedded knowledge": {
                "Input or control techniques": "1. Systematic categorization of unreasonable local explanations 2. Annotation of new boundaries for unreasonable attention",
                "Output or feedback methods": "1. Reasonability Matrix for visualizing model performance changes 2. IoU distribution charts for assessing attention quality"
            },
            "Implementation": "Attention adjustment--Drawing panel; Performance evaluation--Reasonability Matrix"
        }
    ],
    "Results": {
        "Performance": "The average accuracy of the fine-tuned models was 82.95%, with an average IoU of 0.39 and an average proportion of reasonable attention of 89.55%. These performances outperformed both the initial model and the state-of-the-art fine-tuned model without attention.",
        "User feedback": "Participants found DeepFuse useful and easier for understanding model vulnerability. They appreciated the systematic diagnosis process and the direct steering of CNNs. The usability score was 76.88, indicating acceptable usability. Participants also noted the potential for improving model robustness and fairness."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Predominantly algorithmic approaches for handling contextual bias",
                "This study": "Interactive system for direct CNN steering using local explanations"
            },
            {
                "Previous studies": "Manual and heuristic processes for diagnosing model vulnerabilities",
                "This study": "Systematic and automated process for diagnosing and revising CNN vulnerabilities"
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Interactive system for direct CNN steering using local explanations",
                "Result": "Improved model accuracy (82.95%), IoU (0.39), and attention reasonability (89.55%)"
            },
            {
                "Innovation": "Systematic and automated process for diagnosing and revising CNN vulnerabilities",
                "Result": "Participants found the system useful and easier for understanding model vulnerability, with a usability score of 76.88"
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Ordinary Democrats and Republicans",
        "Tasks": "Playing an online casual game to reduce affective polarization",
        "Application Scenarios": "Online interactions between Democrats and Republicans"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Political science research on misperceptions and game studies research",
            "Function": "Reduce negative feelings toward outparty supporters and improve willingness to talk politics with outparty supporters",
            "Embedded knowledge": {
                "Architecture or framework": [
                    "Combines relaxed, playful nonpartisan norms of casual games with corrective information about party supporters’ political views",
                    "Initiates a fun, playful nonpartisan norm around correcting misperceptions"
                ],
                "Tool or tool kits": [
                    "GuesSync! game platform developed using Javascript and React",
                    "Hosted using Google Firebase platform"
                ]
            },
            "Implementation": "Game development--Javascript & React; Hosting--Google Firebase; In-game chat--StreamChat library"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Intergroup conflict literature, psychological reactance theory",
            "Function": "Encourage engagement and reduce partisan hostility through game mechanics",
            "Embedded knowledge": {
                "Input or control techniques": [
                    "Players provide percentage answers using sliders",
                    "Clue-givers provide clues using a hot-cold scale"
                ],
                "Output or feedback methods": [
                    "Visual elements and game mechanics that do not provide partisan cues",
                    "In-game chat for interaction and reflection"
                ]
            },
            "Implementation": "Game interaction--Web platform; Chat interaction--StreamChat library"
        }
    ],
    "Results": {
        "Performance": "Playing the mixed version of the game increased willingness to engage in political discussions with outparty supporters. Democrats playing the treatment versions exhibited warmer feelings towards Republicans. No significant change in outparty feelings for Republicans.",
        "User feedback": "Participants enjoyed playing the treatment game versions as much as the control version. The game was rated as fun, informative, and surprising, with no significant difference in ratings between game versions."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Games with explicit procedural rhetoric promoting desired outcomes",
                "This study": "Embedded design approach with intermixing strategy to implicitly correct misperceptions"
            },
            {
                "Previous studies": "Direct persuasion approaches in games",
                "This study": "Indirect persuasion through a mix of political and nonpolitical content"
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Embedded design approach with intermixing strategy to implicitly correct misperceptions",
                "Result": "Participants enjoyed playing the treatment game versions as much as the control version"
            },
            {
                "Innovation": "Indirect persuasion through a mix of political and nonpolitical content",
                "Result": "Playing the mixed version of the game increased willingness to engage in political discussions with outparty supporters"
            }
        ]
    }
}

{
    "Target Definition": {
        "Target User Group": "Factory floor workers in the shipping and receiving department",
        "Tasks": "Packing orders, building custom crates, performing quality assurance, and creating digital records for product quality",
        "Application Scenarios": "Digitalization of the shipping and receiving department at a small manufacturer"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Grounded theory practices",
            "Function": "Create quality documentation in the shipping department",
            "Embedded knowledge": {
                "Architecture or framework": "1. Digital workflow tool for Industry 4.0 manufacturers. 2. Real-time tracking via a web-based data dashboard.",
                "Tool or tool kits": "1. Google Glass Enterprise Edition devices. 2. Mobile application for digitizing work instructions and inspection procedures."
            },
            "Implementation": "Digital workflow tool--Google Glass Enterprise Edition; Mobile application--Personal devices"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Grounded theory practices",
            "Function": "Enable access to electronic work instructions and create digital records for product quality",
            "Embedded knowledge": {
                "Input or control techniques": "1. Scanning barcodes with mobile phones. 2. Capturing item pictures to eliminate the need for quality check sheets.",
                "Output or feedback methods": "1. Automatic generation of PDF reports for each order. 2. Text message notifications for order updates."
            },
            "Implementation": "Barcode scanning--Mobile application; Picture capturing--Mobile application"
        }
    ],
    "Results": {
        "Performance": "The intervention provided detailed documentation of order contents, reduced errors, and improved quality control. However, it introduced redundancy and slowed down the process due to the high number of pictures required per order.",
        "User feedback": "Shipping employees appreciated the mobility and familiarity of the mobile application but found the process of taking numerous pictures tedious and time-consuming. The intervention changed the dynamics of work and power within the team, leading to mixed reactions."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Traditional methods of quality assurance and documentation using paper and stationary computer terminals.",
                "This study": "Introduced mobile devices and augmented reality to create digital records and improve documentation processes."
            },
            {
                "Previous studies": "Limited access to order information and reliance on paper documentation.",
                "This study": "Enabled real-time access to order information and electronic work instructions through mobile devices."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Introduced mobile devices and augmented reality to create digital records and improve documentation processes.",
                "Result": "Provided detailed documentation of order contents, reduced errors, and improved quality control but introduced redundancy and slowed down the process."
            },
            {
                "Innovation": "Enabled real-time access to order information and electronic work instructions through mobile devices.",
                "Result": "Changed the dynamics of work and power within the team, leading to mixed reactions from shipping employees."
            }
        ]
    }
}

{
    "Target Definition": {
        "Target User Group": "Older adults and their adult children",
        "Tasks": "Sharing in-home activity data to balance privacy and awareness",
        "Application scenarios": "Aging adults living independently while their children monitor their well-being from a distance"
    },
    "Contributions": [
        {
            "Innovation type": "Design",
            "Supporting knowledge": "User-centered design process, iterative design, privacy vs. awareness tradeoff",
            "Function": "Mitigate the privacy needs of aging adults while providing necessary information to adult children",
            "Embedded knowledge": {
                "Prototype, script or models": "1. iFloor visualization system: a floor plan-based visualization that highlights important areas and activities. 2. Activity panels for crucial and customized activities. 3. Dynamic visual effects for real-time safety status."
            },
            "Implementation": "Indoor location data visualization--iFloor; Historical data representation--ambient grey dots; Real-time safety status--color-coded avatar"
        }
    ],
    "Results": {
        "Performance": "iFloor provided a good balance between privacy and awareness. Raw video had 100% correctness but was privacy-invasive. iFloor had 80% correctness and was more privacy-preserving than video. Abstract art had 25% correctness and was the least informative.",
        "User feedback": "Older adults felt more comfortable sharing iFloor (1.6875/2) compared to raw video (1.3125/2). Adult children found iFloor useful (1.6/2) but less so than raw video (1.95/2). Abstract art was the least useful (0.35/2) and least comfortable to share (1.3/2)."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Used raw video or abstract art for monitoring, which either invaded privacy or lacked informativeness.",
                "This study": "Developed iFloor, a floor plan-based visualization that balances privacy and awareness by using indoor location data and dynamic visual effects."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Developed iFloor, a floor plan-based visualization that balances privacy and awareness by using indoor location data and dynamic visual effects.",
                "Result": "iFloor provided a good balance between privacy and awareness. Raw video had 100% correctness but was privacy-invasive. iFloor had 80% correctness and was more privacy-preserving than video. Abstract art had 25% correctness and was the least informative."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Program staff, callers (CCEs and hospital supervisors), and beneficiaries in a call-based maternal and child health program in India",
        "Tasks": "Identifying beneficiaries likely to drop out of the program and increasing their engagement through human intervention",
        "Application scenarios": "Large-scale public health intervention for maternal and child health in resource-constrained settings"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Restless Multi-Armed Bandit (RMAB) framework",
            "Function": "Optimize resource allocation by identifying beneficiaries at risk of dropping out and targeting them for human intervention",
            "Embedded knowledge": {
                "Architecture or framework": "1. Uses historical call log data and socio-demographic features to predict engagement. 2. Designed to maximize engagement by selecting beneficiaries who could benefit from human intervention.",
                "Tool or tool kits": "1. Web application for distributing calls. 2. Mobile application for callers to receive and log call outcomes."
            },
            "Implementation": "Prediction--Restless Multi-Armed Bandit (RMAB) framework; Call distribution--Web application; Call logging--Mobile application"
        }
    ],
    "Results": {
        "Performance": "The ML model showed a 30% increase in listenership compared to the current standard of care group in initial testing. Ongoing evaluation shows comparable performance to a round-robin approach.",
        "User feedback": "Callers found the calls helpful for building rapport and getting feedback from beneficiaries. Hospital supervisors had higher call success rates due to in-person interactions. Callers faced challenges with low call success rates and varied engagement."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Manual identification of beneficiaries and limited human resources for follow-up calls.",
                "This study": "Automated identification of beneficiaries at risk of dropping out using the Restless Multi-Armed Bandit (RMAB) framework, optimizing resource allocation and increasing engagement."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Automated identification of beneficiaries at risk of dropping out using the Restless Multi-Armed Bandit (RMAB) framework, optimizing resource allocation and increasing engagement.",
                "Result": "The ML model showed a 30% increase in listenership compared to the current standard of care group in initial testing. Ongoing evaluation shows comparable performance to a round-robin approach."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Users of AI-assisted decision-making systems",
        "Tasks": "Judging the sentiment of movie reviews with AI assistance",
        "Application Scenarios": "AI-assisted decision-making in sentiment analysis tasks"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Human-centered XAI efforts, Malle’s theory of explanation",
            "Function": "Generate selective explanations by leveraging human input to align AI explanations with user preferences",
            "Embedded knowledge": {
                "Architecture or framework": [
                    "1. A general framework for generating selective explanations by leveraging human input on a small dataset.",
                    "2. A belief prediction model to generalize from input gathered to predict the recipient’s preferences."
                ],
                "Tool or tool kits": [
                    "1. Belief prediction model: A word-level logistic regression model using GloVe embeddings."
                ]
            },
            "Implementation": "Sentiment analysis--BERT model; Explanation generation--LIME; Belief prediction model--Logistic regression with GloVe embeddings"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Human-centered XAI efforts, Malle’s theory of explanation",
            "Function": "Improve user understanding and decision-making by providing explanations that align with user preferences",
            "Embedded knowledge": {
                "Input or control techniques": [
                    "1. Open-ended input: Users provide words they consider important for sentiment judgment.",
                    "2. Critique-based input: Users critique the importance of words highlighted by the AI."
                ],
                "Output or feedback methods": [
                    "1. Selective explanations: Highlighting relevant words and graying out irrelevant words based on user input."
                ]
            },
            "Implementation": "Explanation presentation--Saliency highlights with color and shade variations"
        }
    ],
    "Results": {
        "Performance": "Selective explanations improved decision accuracy (74.6% to 81.8%) and reduced over-reliance on AI (44.4% to 31.5%) in random samples.",
        "User feedback": "Selective explanations improved perceived understanding of AI (3.0 to 3.9) but did not significantly affect perceived usefulness or subjective workload."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Existing XAI techniques often provide explanations that are hard to use and lack effectiveness.",
                "This study": "Introduced a framework for generating selective explanations by leveraging human input to align AI explanations with user preferences."
            },
            {
                "Previous studies": "Feature-based explanations often fail to align with user preferences, leading to over-reliance on AI.",
                "This study": "Developed a belief prediction model to predict user preferences and generate selective explanations, improving decision accuracy and reducing over-reliance."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Introduced a framework for generating selective explanations by leveraging human input to align AI explanations with user preferences.",
                "Result": "Selective explanations improved decision accuracy (74.6% to 81.8%) and reduced over-reliance on AI (44.4% to 31.5%) in random samples."
            },
            {
                "Innovation": "Developed a belief prediction model to predict user preferences and generate selective explanations, improving decision accuracy and reducing over-reliance.",
                "Result": "Selective explanations improved perceived understanding of AI (3.0 to 3.9) but did not significantly affect perceived usefulness or subjective workload."
            }
        ]
    }
}

{
    "Target Definition": {
        "Target User Group": "Friends who live in separate households",
        "Tasks": "Configuring and using connected physical artifacts for social connection",
        "Application Scenarios": "Staying connected with family and friends through ubiquitous computing in home environments"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Technology probe approach, Ubiquitous Computing concepts",
            "Function": "Enable users to create an ecosystem of connected artifacts for social connection",
            "Embedded knowledge": {
                "Architecture or framework": [
                    "1. AR-based technology probe enabling customizable and scalable connections.",
                    "2. Use of printed AR markers to convert any object into a medium for social connection."
                ],
                "Tool or tool kits": [
                    "1. Setup app for establishing connections between endpoints.",
                    "2. Connection app on AR glasses for sending and receiving content."
                ]
            },
            "Implementation": "AR markers--Printed paper; Setup app--iPhone 8 or later; Connection app--Snap Next Generation Spectacles; Data storage--AWS DynamoDB and S3"
        }
    ],
    "Results": {
        "Performance": "Participants sent 1,840 Sparkles and 576 Ghosts, showing active engagement. The study revealed that ecosystems of multiple endpoints improve social connection and sense of presence.",
        "User feedback": "Participants reported decreased feelings of loneliness and increased feelings of connectedness with their study partners. They valued the flexibility of choosing and configuring their own artifacts, and appreciated the serendipitous and ritualistic communication patterns."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Prior systems often designed with fixed configurations and single pairs of connected devices.",
                "This study": "Empowered users to design and curate their own set of existing objects as endpoints for social connection, revealing new artifacts and configurations."
            },
            {
                "Previous studies": "Focused on single-connection systems for social connection.",
                "This study": "Explored how an ecosystem of multiple artifacts can be used, uncovering different behavior patterns and perspectives for social connection."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Empowered users to design and curate their own set of existing objects as endpoints for social connection, revealing new artifacts and configurations.",
                "Result": "Participants valued the flexibility of choosing and configuring their own artifacts, and appreciated the serendipitous and ritualistic communication patterns."
            },
            {
                "Innovation": "Explored how an ecosystem of multiple artifacts can be used, uncovering different behavior patterns and perspectives for social connection.",
                "Result": "Participants reported decreased feelings of loneliness and increased feelings of connectedness with their study partners. They valued the flexibility of choosing and configuring their own artifacts, and appreciated the serendipitous and ritualistic communication patterns."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Users of online advertising platforms",
        "Tasks": "Evaluate the efficacy of personalized ad targeting and user responses to different ad delivery methods",
        "Application Scenarios": "Online advertising environments where users are exposed to targeted ads"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Algorithm auditing, user behavior analysis",
            "Function": "Conduct sociotechnical audits to evaluate the interplay between algorithms and users",
            "Embedded knowledge": {
                "Architecture or framework": [
                    "1. Two-phase study design: observational phase followed by intervention phase",
                    "2. Intervenr platform: browser extension and web application for longitudinal audits"
                ],
                "Tool or tool kits": [
                    "1. AdNauseam integration for ad detection and collection",
                    "2. Custom scripts for link resolving, image downloading, and person detection"
                ]
            },
            "Implementation": "Browser extension--Google Chrome; Web application--Django; Data analysis--Python scripts on Amazon EC2"
        }
    ],
    "Results": {
        "Performance": "Targeted ads performed moderately well with users showing low-to-moderate interest and representativity. Recognition rates were around 41%, with a false recognition rate of 21%.",
        "User feedback": "Participants generally had positive experiences with the study, with low self-reported non-compliance and minimal data redaction. Participants showed a preference for personalized ads over swapped ads, but acclimated to new ads over time."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Algorithm audits focused on technical components without considering user interactions.",
                "This study": "Introduced sociotechnical audits to evaluate both technical and human components, using a two-phase study design and the Intervenr platform."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Introduced sociotechnical audits to evaluate both technical and human components, using a two-phase study design and the Intervenr platform.",
                "Result": "Targeted ads performed moderately well with users showing low-to-moderate interest and representativity. Recognition rates were around 41%, with a false recognition rate of 21%."
            }
        ]
    }
}
Error decoding JSON: Invalid \escape: line 1 column 1104 (char 1103)
{
    "Target Definition": {
        "Target User Group": "Diverse youth, particularly those from underrepresented backgrounds in tech",
        "Tasks": "Identifying algorithmic bias and designing future systems to address problematic technology behavior",
        "Application Scenarios": "Educational workshops and family-inclusive activities to explore fairness in AI"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Algorithm auditing, everyday algorithm auditing",
            "Function": "Enable youth to identify and articulate algorithmic bias and suggest ways to mitigate it",
            "Embedded knowledge": {
                "Architecture or framework": [
                    "1. Collaborative sensemaking framework: Engages youth and parents in discussions about AI bias.",
                    "2. Youth-inclusive algorithm auditing framework: Supports youth in identifying and reporting algorithmic biases."
                ],
                "Tool or tool kits": [
                    "1. Bias Identification Activity: Uses AI examples to help youth recognize bias.",
                    "2. Design Activity: Encourages youth to create systems for reporting and mitigating AI bias."
                ]
            },
            "Implementation": "Workshops--Educational settings; Bias Identification--Printed AI examples; Design Activity--Crafting materials"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Collaborative learning, peer-to-peer support",
            "Function": "Facilitate youth engagement in identifying and mitigating AI bias through interactive activities",
            "Embedded knowledge": {
                "Input or control techniques": [
                    "1. Reporting mechanisms: Allow users to report potential biases in AI outputs.",
                    "2. Feedback mechanisms: Enable users to provide open-ended feedback on AI behavior."
                ],
                "Output or feedback methods": [
                    "1. User-adjustable outputs: Allow users to modify algorithmic outputs to reflect diversity and inclusion.",
                    "2. Transparency features: Provide warnings or caveats about potential biases in AI outputs."
                ]
            },
            "Implementation": "Workshops--Educational settings; Reporting and feedback--Interactive interfaces"
        },
        {
            "Innovation type": "Design",
            "Supporting knowledge": "Youth-inclusive design, family engagement",
            "Function": "Empower youth to participate in creating fairer AI systems through design activities",
            "Embedded knowledge": {
                "Prototype, script or models": [
                    "1. Youth-designed reporting systems: Prototypes created by youth to report AI bias.",
                    "2. User-adjustable interfaces: Designs that allow users to modify AI outputs for fairness."
                ],
                "Material or crafts": [
                    "1. Crafting materials: Used in design activities to create prototypes.",
                    "2. Printed AI examples: Used as a base for youth to augment with their designs."
                ]
            },
            "Implementation": "Design Activity--Crafting materials; Printed AI examples--Base for designs"
        }
    ],
    "Results": {
        "Performance": "Youth participants were able to identify and articulate algorithmic biases, often in great detail. They suggested various ways to mitigate these biases, including reporting mechanisms, user-adjustable outputs, and transparency features.",
        "User feedback": "Participants, including both youth and parents, found the activities engaging and informative. They appreciated the opportunity to discuss and address algorithmic bias, with many expressing a desire to continue participating in similar activities."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Limited involvement of youth in algorithm auditing and responsible AI discussions.",
                "This study": "Engages diverse youth and their families in identifying and mitigating algorithmic bias through interactive workshops and design activities."
            },
            {
                "Previous studies": "Focus on adult users for everyday algorithm auditing.",
                "This study": "Introduces youth-inclusive algorithm auditing frameworks and activities, emphasizing collaborative learning and family support."
            },
            {
                "Previous studies": "Traditional AI education with limited focus on ethical considerations.",
                "This study": "Combines AI literacy with ethical awareness, empowering youth to critically engage with AI bias and fairness."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Engages diverse youth and their families in identifying and mitigating algorithmic bias through interactive workshops and design activities.",
                "Result": "Youth participants were able to identify and articulate algorithmic biases, often in great detail. They suggested various ways to mitigate these biases, including reporting mechanisms, user-adjustable outputs, and transparency features."
            },
            {
                "Innovation": "Introduces youth-inclusive algorithm auditing frameworks and activities, emphasizing collaborative learning and family support.",
                "Result": "Participants, including both youth and parents, found the activities engaging and informative. They appreciated the opportunity to discuss and address algorithmic bias, with many expressing a desire to continue participating in similar activities."
            },
            {
                "Innovation": "Combines AI literacy with ethical awareness, empowering youth to critically engage with AI bias and fairness.",
                "Result": "Youth participants demonstrated a strong understanding of fairness and bias in AI, with many able to articulate complex ethical considerations and propose solutions for more fair AI systems."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "None",
        "Tasks": "None",
        "Application scenarios": "None"
    },
    "Contributions": [],
    "Results": {
        "Performance": "None",
        "User feedback": "None"
    },
    "Second Extraction": {
        "Innovations": [],
        "Quadruple": []
    }
}
{
    "Target Definition": {
        "Target User Group": "Therapists and laypersons",
        "Tasks": "Assessing post-stroke survivors’ quality of motion",
        "Application Scenarios": "Clinical decision-making in physical stroke rehabilitation assessment"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Human-AI collaborative decision-making; Explainable AI",
            "Function": "Assist therapists and laypersons in assessing post-stroke survivors’ quality of motion",
            "Embedded knowledge": {
                "Architecture or framework": [
                    "1. Utilized salient feature explanations along with counterfactual explanations to enhance analytical review of AI suggestions.",
                    "2. Implemented a web interface using the Gradio library to present AI outputs and explanations."
                ],
                "Tool or tool kits": [
                    "1. SHAP library for identifying salient features.",
                    "2. DiCE library for generating counterfactual explanations."
                ]
            },
            "Implementation": "Rehabilitation assessment--Gradio; AI explanations--SHAP & DiCE"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Cognitive forcing functions to reduce overreliance on AI",
            "Function": "Reduce overreliance on AI outputs and improve analytical review",
            "Embedded knowledge": {
                "Input or control techniques": [
                    "1. Salient feature analysis to highlight important features for assessment.",
                    "2. Counterfactual explanations to describe how input features need to be changed to flip an AI output."
                ],
                "Output or feedback methods": [
                    "1. Radar chart visualization for salient features.",
                    "2. Textual descriptions for counterfactual explanations."
                ]
            },
            "Implementation": "Decision support--Web interface using Gradio"
        }
    ],
    "Results": {
        "Performance": "The human + AI team with counterfactual explanations reduced overreliance on ‘wrong’ AI outputs by 21% compared to salient feature explanations. Laypersons had higher performance degradation when using salient features (18.0 f1-score) compared to counterfactual explanations (14.0 f1-score).",
        "User feedback": "Participants expressed higher trust and reliance on the system with salient feature analysis (73.78 out of 100) compared to the system with counterfactual explanations (45.20 out of 100). However, counterfactual explanations were closer to the actual system performance."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Salient feature explanations to assist decision-making.",
                "This study": "Combined salient feature explanations with counterfactual explanations to reduce overreliance on AI outputs."
            },
            {
                "Previous studies": "AI explanations primarily focused on confirming AI outputs.",
                "This study": "Introduced counterfactual explanations to induce more analytical review and better estimate AI performance."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Combined salient feature explanations with counterfactual explanations to reduce overreliance on AI outputs.",
                "Result": "The human + AI team with counterfactual explanations reduced overreliance on ‘wrong’ AI outputs by 21% compared to salient feature explanations."
            },
            {
                "Innovation": "Introduced counterfactual explanations to induce more analytical review and better estimate AI performance.",
                "Result": "Participants expressed higher trust and reliance on the system with salient feature analysis (73.78 out of 100) compared to the system with counterfactual explanations (45.20 out of 100). However, counterfactual explanations were closer to the actual system performance."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Decision-makers in high-stakes domains like healthcare and finance",
        "Tasks": "Human-AI decision-making with explanations",
        "Application Scenarios": "Decision-making scenarios where AI systems provide predictions and explanations to assist human decision-makers"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Think-aloud protocol; Mixed-methods study",
            "Function": "Understand the role of human intuition on reliance in human-AI decision-making",
            "Embedded knowledge": {
                "Architecture or framework": "1. Identified three types of intuition involved in reasoning about AI predictions and explanations: intuition about the task outcome, features, and AI limitations. 2. Summarized three observed pathways for decision-makers to apply their own intuition and override AI predictions.",
                "Tool or tool kits": "None"
            },
            "Implementation": "Think-aloud protocol--Participants verbalize their thought process; Mixed-methods study--Combines quantitative and qualitative analysis"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Human-centered computing; Collaborative and social computing",
            "Function": "Improve human-AI complementary performance by providing effective explanations",
            "Embedded knowledge": {
                "Input or control techniques": "1. Feature-based explanations: Presenting feature contributions in a bar chart or highlighting text. 2. Example-based explanations: Providing nearest neighbors from the training set with AI predictions and ground truth labels.",
                "Output or feedback methods": "1. Example-based explanations: Less disruptive and more compatible with natural intuition formation. 2. Feature-based explanations: Can increase overreliance when AI predictions are incorrect."
            },
            "Implementation": "Feature-based explanations--LIME; Example-based explanations--Nearest neighbors from training set"
        }
    ],
    "Results": {
        "Performance": "Example-based explanations led to complementary human-AI performance with higher accuracy than human or AI alone. Feature-based explanations did not improve decision outcomes and increased overreliance on incorrect AI predictions.",
        "User feedback": "Participants had mixed preferences: about half favored feature-based explanations for ease of use, while the other half preferred example-based explanations for providing more context and better supporting decision-making."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Focused on feature-based explanations and found mixed results on their effectiveness.",
                "This study": "Identified three types of intuition and three pathways for decision-makers to apply their intuition to override AI predictions, highlighting the effectiveness of example-based explanations."
            },
            {
                "Previous studies": "Examined the impact of explanations on decision-making without deeply understanding the decision-making process.",
                "This study": "Used a think-aloud protocol and mixed-methods study to investigate the decision-making process, providing a more holistic understanding of how intuition affects reliance on AI predictions and explanations."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Identified three types of intuition and three pathways for decision-makers to apply their intuition to override AI predictions, highlighting the effectiveness of example-based explanations.",
                "Result": "Example-based explanations led to complementary human-AI performance with higher accuracy than human or AI alone."
            },
            {
                "Innovation": "Used a think-aloud protocol and mixed-methods study to investigate the decision-making process, providing a more holistic understanding of how intuition affects reliance on AI predictions and explanations.",
                "Result": "Participants had mixed preferences: about half favored feature-based explanations for ease of use, while the other half preferred example-based explanations for providing more context and better supporting decision-making."
            }
        ]
    }
}

{
    "Target Definition": {
        "Target User Group": "Multidisciplinary teams of data scientists, clinicians, and HCI researchers",
        "Tasks": "Brainstorming AI concepts, problem formulation, and initial assessment with end users",
        "Application scenarios": "Improving critical care medicine in intensive care units (ICUs)"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Human-centered design, AI capabilities, and examples",
            "Function": "Identify buildable and desirable AI use cases for critical care medicine",
            "Embedded knowledge": {
                "Architecture or framework": "1. AI Brainstorming Kit: A resource to help HCI experts facilitate AI concept ideation within multidisciplinary teams. 2. Do-Reason-Know worksheet: Captures interaction, model reasoning, and data requirements.",
                "Tool or tool kits": "1. AI Brainstorming Kit: Helps identify low-risk, high-value AI concepts where moderate AI performance can create value."
            },
            "Implementation": "Brainstorming workshops--In-person sessions; Concept detailing--Do-Reason-Know worksheet"
        },
        {
            "Innovation type": "Design",
            "Supporting knowledge": "Human-centered design principles",
            "Function": "Facilitate effective ideation and problem formulation for AI concepts in critical care",
            "Embedded knowledge": {
                "Prototype, script or models": "1. AI Brainstorming Kit: A set of AI capabilities and examples to scaffold ideation. 2. Do-Reason-Know worksheet: A tool to detail AI concepts in terms of action, model reasoning, and data.",
                "Material or crafts": "1. AI capability abstractions and examples: Used to prompt ideation. 2. Do-Reason-Know worksheet: Used to detail concepts and separate interaction form and AI inference."
            },
            "Implementation": "Concept sketches--Low fidelity sketches; Co-design workshops--In-person sessions with nurses and respiratory therapists"
        }
    ],
    "Results": {
        "Performance": "The study identified clinically relevant and buildable AI concepts, with a broader design space and lower-risk, medium-value concepts. The Do-Reason-Know worksheet helped detail concepts and identify potential data issues early on.",
        "User feedback": "Participants found the concepts valuable and provided detailed feedback on interaction design and data requirements. They expressed a desire for more stakeholder involvement and highlighted the importance of trustworthy data."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Traditional user-centered design approaches often result in unbuildable or unwanted AI concepts.",
                "This study": "Blended user-centered and tech-centered approaches using AI capabilities and examples to generate buildable and desirable AI concepts."
            },
            {
                "Previous studies": "Existing brainstorming methods do not effectively separate interaction form and AI inference.",
                "This study": "Introduced the Do-Reason-Know worksheet to detail concepts in terms of action, model reasoning, and data, separating interaction form and AI inference."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Blended user-centered and tech-centered approaches using AI capabilities and examples to generate buildable and desirable AI concepts.",
                "Result": "The study identified clinically relevant and buildable AI concepts, with a broader design space and lower-risk, medium-value concepts."
            },
            {
                "Innovation": "Introduced the Do-Reason-Know worksheet to detail concepts in terms of action, model reasoning, and data, separating interaction form and AI inference.",
                "Result": "The Do-Reason-Know worksheet helped detail concepts and identify potential data issues early on."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "General users involved in trip planning",
        "Tasks": "Trip planning with AI assistance",
        "Application Scenarios": "Decision-making in trip planning considering time and budget constraints"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Trustworthiness Assessment Model (TrAM)",
            "Function": "Investigate the impact of task complexity and uncertainty on human-AI decision-making",
            "Embedded knowledge": {
                "Architecture or framework": "1. Task complexity defined by the number of constraints. 2. Task uncertainty operationalized using diagnostic and prognostic tasks.",
                "Tool or tool kits": "None"
            },
            "Implementation": "Trip-planning task--Custom interface; AI system accuracy--66.7%"
        }
    ],
    "Results": {
        "Performance": "Participants tended to rely more on AI in tasks with higher complexity and uncertainty. Users showed higher engagement in prognostic scenarios. Appropriate reliance on AI varied significantly depending on task complexity and uncertainty.",
        "User feedback": "Participants demonstrated a heavy reliance on AI advice during complex and uncertain tasks. Trust in the AI system remained consistent regardless of task complexity or uncertainty."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Focused on generic decision-making scenarios or tasks with low to medium complexity.",
                "This study": "Investigated the impact of task complexity and uncertainty on human-AI decision-making using a trip-planning task."
            },
            {
                "Previous studies": "Did not systematically explore task characteristics in human-AI decision-making.",
                "This study": "Proposed the lens of diagnostic and prognostic tasks to model uncertainty in decision-making."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Investigated the impact of task complexity and uncertainty on human-AI decision-making using a trip-planning task.",
                "Result": "Participants tended to rely more on AI in tasks with higher complexity and uncertainty. Users showed higher engagement in prognostic scenarios."
            },
            {
                "Innovation": "Proposed the lens of diagnostic and prognostic tasks to model uncertainty in decision-making.",
                "Result": "Appropriate reliance on AI varied significantly depending on task complexity and uncertainty. Trust in the AI system remained consistent regardless of task complexity or uncertainty."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Users interacting with virtual objects in various shapes",
        "Tasks": "Rendering virtual compliance in different shapes through electrotactile stimulation",
        "Application scenarios": "Enhancing physical objects, graphical user interfaces, and virtual reality experiences with virtual compliance"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Grain-based vibrotactile compliance illusion",
            "Function": "Render compliance in distinct shapes through electrotactile stimulation",
            "Embedded knowledge": {
                "Architecture or framework": "1. Grain-based electrotactile compliance illusion framework. 2. Thin, lightweight, flexible finger-worn interface.",
                "Tool or tool kits": "1. 3 × 3 electrode array. 2. Force-sensitive resistor (FSR)."
            },
            "Implementation": "Electrode array printing--Silver nanoparticle-based ink; Force sensing--Interlink FSR 402; Control circuit--Teensy 3.5"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Grain-based vibrotactile compliance illusion",
            "Function": "Render compliance with specific shapes through electrotactile stimulation",
            "Embedded knowledge": {
                "Input or control techniques": "1. Generate electrical pulses in response to force changes. 2. Use time-division scanning for multiple electrodes.",
                "Output or feedback methods": "1. Render compliance with shapes like squares, lines, and triangles. 2. Adjust compliance magnitude with grain and electrode parameters."
            },
            "Implementation": "Shape rendering--3 × 3 electrode array; Compliance adjustment--Grain and electrode parameters"
        }
    ],
    "Results": {
        "Performance": "The study demonstrated that the proposed electrotactile compliance illusion could effectively create virtual compliance, adjust the compliance magnitude, and render compliance in specific shapes. The user study confirmed significant differences in perceived compliance with varying grain levels and electrode conditions.",
        "User feedback": "Participants described the induced sensation as elastic, bouncy, squishy, and soft. They compared high-rated conditions to objects like sponges and foam, and low-rated conditions to harder objects like erasers. Some participants noted the realism of the induced compliance, with medium intensity feeling more natural."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Grain-based vibrotactile compliance illusion with low spatial resolution and bulky form factor.",
                "This study": "Grain-based electrotactile compliance illusion with high spatial resolution and thin, flexible form factor."
            },
            {
                "Previous studies": "Vibrotactile actuators for compliance rendering with limited shapes and sizes.",
                "This study": "Electrotactile stimulation rendering compliance in distinct shapes like squares, lines, and triangles."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Grain-based electrotactile compliance illusion with high spatial resolution and thin, flexible form factor.",
                "Result": "Effectively created virtual compliance, adjusted compliance magnitude, and rendered compliance in specific shapes."
            },
            {
                "Innovation": "Electrotactile stimulation rendering compliance in distinct shapes like squares, lines, and triangles.",
                "Result": "Participants perceived compliance with specific shapes and provided qualitative feedback on the induced sensations."
            }
        ]
    }
}

{
    "Target Definition": {
        "Target User Group": "Non-technical end users",
        "Tasks": "Teaching a system to perform tasks using natural language in a video game setting",
        "Application Scenarios": "Interactive task learning in video games"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Interactive Task Learning (ITL) framework, Hierarchical Task Networks (HTNs)",
            "Function": "Enable machines to learn tasks incrementally from natural language instructions",
            "Embedded knowledge": {
                "Architecture or framework": "1. Integration of GPT subroutines for specific tasks within a classical learning algorithm. 2. Use of confrmatory dialogs and undo operations to mitigate errors.",
                "Tool or tool kits": "1. VAL system for interactive task learning. 2. GPT subroutines for semantic parsing, argument selection, and task generalization."
            },
            "Implementation": "Overcooked-AI--Game environment; GPT-3.5-turbo and GPT-4--Language models"
        }
    ],
    "Results": {
        "Performance": "VAL successfully learned and executed tasks in a video game environment. Nine out of twelve participants were able to teach VAL to complete all milestones. The success rates for GPT subroutines were high, with segmentGPT at 93%, mapGPT at 97% (GPT-4), and groundGPT at 88%.",
        "User feedback": "Most participants found VAL easy to use and felt it understood their instructions. However, some found the confrmatory dialogs tedious. The user survey showed positive responses, with high agreement that VAL performed tasks correctly and that the knowledge display was easy to understand."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Classical syntactic and semantic parsers for language-driven task acquisition",
                "This study": "Integration of GPT subroutines for specific tasks within a classical learning algorithm to handle natural language more flexibly and accurately."
            },
            {
                "Previous studies": "Limited user interactions requiring user training in system-specific syntax",
                "This study": "Use of natural language dialogs and confrmatory prompts to make interactions more intuitive and reduce the need for user training."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Integration of GPT subroutines for specific tasks within a classical learning algorithm to handle natural language more flexibly and accurately.",
                "Result": "VAL successfully learned and executed tasks in a video game environment. Nine out of twelve participants were able to teach VAL to complete all milestones. The success rates for GPT subroutines were high, with segmentGPT at 93%, mapGPT at 97% (GPT-4), and groundGPT at 88%."
            },
            {
                "Innovation": "Use of natural language dialogs and confrmatory prompts to make interactions more intuitive and reduce the need for user training.",
                "Result": "Most participants found VAL easy to use and felt it understood their instructions. However, some found the confrmatory dialogs tedious. The user survey showed positive responses, with high agreement that VAL performed tasks correctly and that the knowledge display was easy to understand."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Consumers seeking nutritional information",
        "Tasks": "Generating food product explanations",
        "Application Scenarios": "Providing nutrition information for food selection"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Mixed-methods approach with registered dietitians",
            "Function": "Generate accurate and personalized nutrition information",
            "Embedded knowledge": {
                "Architecture or framework": [
                    "1. Design guidelines for prompting LLMs for nutrition information",
                    "2. Iterative process with focus groups for refining outputs"
                ],
                "Tool or tool kits": [
                    "1. Customized GPT prototype named The Food Product Nutrition Assistant",
                    "2. Template instructions for generating food product explanations"
                ]
            },
            "Implementation": "Nutrition information validation--Registered Dietitians; GPT-4 outputs--OpenAI GPT-4"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Prompt engineering and AI fine-tuning",
            "Function": "Provide detailed and tailored food product explanations",
            "Embedded knowledge": {
                "Input or control techniques": [
                    "1. Use of specific levels of prompt specificity to guide LLM outputs",
                    "2. Inclusion of Nutrition Facts label and ingredients list in prompts"
                ],
                "Output or feedback methods": [
                    "1. Structured format with clear headings and bullet points",
                    "2. Example sentences to guide language and style"
                ]
            },
            "Implementation": "Food product explanations--Customized GPT prototype; User dietary goals--Prompt inputs"
        }
    ],
    "Results": {
        "Performance": "The customized GPT prototype provided more accurate and tailored food product explanations, aligning better with dietitian standards. The inclusion of detailed nutritional information and example sentences improved the clarity and relevance of the outputs.",
        "User feedback": "Registered dietitians found the refined outputs to be more comprehensive and easier to understand. They appreciated the structured format and the alignment with dietary guidelines, although some limitations in real-time food cost information and SNAP/WIC eligibility were noted."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "General LLM outputs often contain nutritional misinformation and lack regulatory health guidelines.",
                "This study": "Customized GPT prototype with detailed prompt instructions and example sentences, validated by registered dietitians."
            },
            {
                "Previous studies": "LLM outputs are often narrative and lack clear structure, making them difficult to interpret.",
                "This study": "Structured format with clear headings and bullet points, guided by example sentences."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Customized GPT prototype with detailed prompt instructions and example sentences, validated by registered dietitians.",
                "Result": "Provided more accurate and tailored food product explanations, aligning better with dietitian standards."
            },
            {
                "Innovation": "Structured format with clear headings and bullet points, guided by example sentences.",
                "Result": "Improved the clarity and relevance of the outputs, making them easier to understand for users."
            }
        ]
    }
}

{
    "Target Definition": {
        "Target User Group": "Programmers using AI-assisted coding tools",
        "Tasks": "Interactions with code-recommendation systems like GitHub Copilot",
        "Application scenarios": "Programming tasks in an IDE environment"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Human-AI collaboration, User modeling",
            "Function": "Understand and model user behavior and costs in AI-assisted programming",
            "Embedded knowledge": {
                "Architecture or framework": [
                    "1. CodeRec User Programming States (CUPS) taxonomy to categorize programmer activities",
                    "2. CUPS diagram to visualize transitions between states"
                ],
                "Tool or tool kits": [
                    "1. Retrospective labeling tool for coding sessions",
                    "2. Telemetry data collection system integrated with Copilot"
                ]
            },
            "Implementation": "Telemetry data collection--Copilot; Retrospective labeling--Custom tool; Analysis--Python"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Human-AI collaboration, User modeling",
            "Function": "Improve interaction efficiency and reduce cognitive load in AI-assisted programming",
            "Embedded knowledge": {
                "Input or control techniques": [
                    "1. Prompt crafting to refine AI-generated code suggestions",
                    "2. Deferred thought mechanism to accept suggestions for later verification"
                ],
                "Output or feedback methods": [
                    "1. CUPS diagram to visualize user state transitions",
                    "2. Metrics for time spent in different states to identify inefficiencies"
                ]
            },
            "Implementation": "Prompt crafting--IDE; Deferred thought--IDE; Visualization--Python"
        }
    ],
    "Results": {
        "Performance": "The study showed that programmers spend a significant amount of time (34.3%) verifying and editing Copilot suggestions. The total time spent on Copilot-related activities was over 50% of the session time, indicating a substantial impact on user behavior.",
        "User feedback": "Participants generally felt more productive and in flow with Copilot, with 17 out of 21 agreeing that they completed tasks faster. However, concerns about code quality and potential bugs were noted by 6 participants."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Limited understanding of user behavior with AI code suggestions",
                "This study": "Developed CUPS taxonomy and diagrams to model and visualize user behavior and costs"
            },
            {
                "Previous studies": "Basic metrics like suggestion acceptance rates",
                "This study": "Introduced detailed metrics for time spent in various states and adjusted verification time"
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Developed CUPS taxonomy and diagrams to model and visualize user behavior and costs",
                "Result": "The study showed that programmers spend a significant amount of time (34.3%) verifying and editing Copilot suggestions. The total time spent on Copilot-related activities was over 50% of the session time, indicating a substantial impact on user behavior."
            },
            {
                "Innovation": "Introduced detailed metrics for time spent in various states and adjusted verification time",
                "Result": "Participants generally felt more productive and in flow with Copilot, with 17 out of 21 agreeing that they completed tasks faster. However, concerns about code quality and potential bugs were noted by 6 participants."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "People with Blindness",
        "Tasks": "Co-creating sound-based mementos",
        "Application Scenarios": "Personal and social reminiscence for people with blindness"
    },
    "Contributions": [
        {
            "Innovation type": "Design",
            "Supporting knowledge": "Research through Design, Co-design",
            "Function": "Support personal and social experiences of reminiscence through sound",
            "Embedded knowledge": {
                "Prototype, script or models": "1. Three types of sonic mementos: Encapsulation and Condensation, Augmentation and Expansion, Re-imagination and Re-creation",
                "Material or crafts": "1. Use of personal audio recordings and sonically significant objects"
            },
            "Implementation": "Co-design workshop--3 hours; Audio recordings--Personal archives; Sound editing software--Free online sound databases and microphones"
        }
    ],
    "Results": {
        "Performance": "The study successfully created three types of sonic mementos that encapsulate, augment, and re-imagine personal audio recordings into more meaningful sonic memories.",
        "User feedback": "Participants appreciated the emotional depth and reflective nature of the sonic mementos. They found the process of co-creating these mementos to be engaging and meaningful, facilitating a deeper connection with their memories."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Focused on overcoming practical challenges such as navigation and usability of digital services for people with blindness.",
                "This study": "Explored how audio can enrich personal and social experiences of reminiscence for people with blindness."
            },
            {
                "Previous studies": "Limited research on the experience of reminiscence and remembering for people with blindness.",
                "This study": "Investigated the design of sound memories together with people with blindness through a 12-month co-creative design process."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Explored how audio can enrich personal and social experiences of reminiscence for people with blindness.",
                "Result": "Participants appreciated the emotional depth and reflective nature of the sonic mementos."
            },
            {
                "Innovation": "Investigated the design of sound memories together with people with blindness through a 12-month co-creative design process.",
                "Result": "The study successfully created three types of sonic mementos that encapsulate, augment, and re-imagine personal audio recordings into more meaningful sonic memories."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "General users interested in thermal perception and interaction",
        "Tasks": "Investigate the nature of thermal masking on human arms",
        "Application scenarios": "Human-computer thermal interfaces, large-scale thermal displays, VR and AR immersive environments"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Thermal referral, sensory masking",
            "Function": "Investigate thermal masking and its properties",
            "Embedded knowledge": {
                "Architecture or framework": "1. Thermal and vibrotactile actuators setup on the forearm. 2. Non-uniform thermal redistribution in thermal referral.",
                "Tool or tool kits": "1. Peltier-based thermal actuator. 2. ERM vibrotactile actuators."
            },
            "Implementation": "Thermal stimulus--Peltier-based thermal actuator; Tactile stimulus--ERM vibrotactile actuators; Power supply--Programmable digital power supply (Korad KD6005P)"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Thermal referral, sensory masking",
            "Function": "Explore the effects of thermal masking in terms of temperature, distance, and placement",
            "Embedded knowledge": {
                "Input or control techniques": "1. Simultaneous activation of thermal and vibrotactile actuators. 2. Placement of actuators at varying distances and on opposite sides of the arm.",
                "Output or feedback methods": "1. Perceived thermal sensations at the tactile location. 2. Non-uniform thermal redistribution."
            },
            "Implementation": "Thermal and tactile stimuli--Forearm; Data collection--Tablet with stylus pen"
        }
    ],
    "Results": {
        "Performance": "The study showed that thermal masking is more likely to occur in warm conditions and can reach up to 24 cm from the thermal site. Masking can also occur on the opposite side of the arm.",
        "User feedback": "Participants reported clear thermal sensations and were able to distinguish between different referral states. The perceived thermal area was generally larger than the actual size of the actuators."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Thermal referral relies on spatial summation and uniform redistribution of thermal sensations.",
                "This study": "Demonstrated non-uniform thermal redistribution and complete attenuation of the original thermal sensation by the illusory thermal sensation."
            },
            {
                "Previous studies": "Sensory masking primarily studied in auditory, tactile, and visual stimuli.",
                "This study": "Discovered thermal masking phenomenon where illusory thermal sensation dominates the original thermal sensation."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Demonstrated non-uniform thermal redistribution and complete attenuation of the original thermal sensation by the illusory thermal sensation.",
                "Result": "Thermal masking is more likely to occur in warm conditions and can reach up to 24 cm from the thermal site. Masking can also occur on the opposite side of the arm."
            },
            {
                "Innovation": "Discovered thermal masking phenomenon where illusory thermal sensation dominates the original thermal sensation.",
                "Result": "Participants reported clear thermal sensations and were able to distinguish between different referral states. The perceived thermal area was generally larger than the actual size of the actuators."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "None",
        "Tasks": "None",
        "Application Scenarios": "None"
    },
    "Contributions": [],
    "Results": {
        "Performance": "None",
        "User feedback": "None"
    },
    "Second Extraction": {
        "Innovations": [],
        "Quadruple": []
    }
}
{
    "Target Definition": {
        "Target User Group": "People with eating disorders",
        "Tasks": "Digital food content consumption",
        "Application Scenarios": "Using smartphones and personal computers to view food content on digital platforms like YouTube"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Dual Systems Theory",
            "Function": "Empower individuals with eating disorders to make informed, conscious, and health-oriented digital food content consumption decisions",
            "Embedded knowledge": {
                "Architecture or framework": "1. FoodCensor monitors and hides passively exposed food content on smartphones and personal computers. 2. Prompts reflective questions for users when they spontaneously search for food content.",
                "Tool or tool kits": "1. FoodCensor mobile application for Android devices. 2. Google Chrome Extension for the Chrome browser."
            },
            "Implementation": "UI component monitoring--Android Accessibility API; Content detection--Rule-based method with food name and food-related keyword dictionaries; Intervention display--Custom CSS class and MutationObserver for Chrome Extension"
        }
    ],
    "Results": {
        "Performance": "FoodCensor significantly reduced the proportion of food videos played and suggested on YouTube. The experimental group showed a significant reduction in food content consumption and improved self-awareness of their digital food content consumption habits.",
        "User feedback": "Experimental group participants found FoodCensor helpful in regulating exposure to food content and preventing the development of their eating disorder symptoms. They reported increased self-awareness and a reduction in obsessive thoughts about food."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Previous studies did not provide adequate support to mitigate the detrimental effects of digital food content on individuals with eating disorders.",
                "This study": "FoodCensor introduces a system that monitors and hides food content, prompts reflective questions, and informs users about the negative consequences of eating disorder behaviors."
            },
            {
                "Previous studies": "Previous studies did not leverage the Dual Systems Theory to address challenges posed by digital food content.",
                "This study": "FoodCensor uses the Dual Systems Theory to shift users from automatic responses (System 1) to conscious evaluation (System 2) when consuming digital food content."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "FoodCensor introduces a system that monitors and hides food content, prompts reflective questions, and informs users about the negative consequences of eating disorder behaviors.",
                "Result": "FoodCensor significantly reduced the proportion of food videos played and suggested on YouTube. The experimental group showed a significant reduction in food content consumption and improved self-awareness of their digital food content consumption habits."
            },
            {
                "Innovation": "FoodCensor uses the Dual Systems Theory to shift users from automatic responses (System 1) to conscious evaluation (System 2) when consuming digital food content.",
                "Result": "Experimental group participants found FoodCensor helpful in regulating exposure to food content and preventing the development of their eating disorder symptoms. They reported increased self-awareness and a reduction in obsessive thoughts about food."
            }
        ]
    }
}

{
    "Target Definition": {
        "Target User Group": "Users of visual analytics tools",
        "Tasks": "Measuring decision-making quality in visual analytics",
        "Application scenarios": "Decision-making under uncertainty in visual analytics"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Benjamini-Hochberg procedure, multiple comparisons problem",
            "Function": "Improve decision quality and reduce false discoveries in visual analytics",
            "Embedded knowledge": {
                "Architecture or framework": "1. Incentive structure to reward cautious decision-making. 2. Various designs for communicating uncertainty.",
                "Tool or tool kits": "None"
            },
            "Implementation": "Crowd-sourced study--Amazon Mechanical Turk; Visual analytics tools--Tableau, PowerBI"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Uncertainty visualization techniques",
            "Function": "Help users make better decisions by visualizing uncertainty",
            "Embedded knowledge": {
                "Input or control techniques": "None",
                "Output or feedback methods": "1. 50% confidence intervals. 2. Probability density functions."
            },
            "Implementation": "Visualizations--Scatterplot, CI, PDF"
        }
    ],
    "Results": {
        "Performance": "Participants in the CI and PDF conditions made fewer false positives than the uncorrected benchmark but more than the Benjamini-Hochberg benchmark. The average false discovery rate was 34% in the PDF condition and 39% in the CI condition.",
        "User feedback": "Participants reported using various strategies, including counting points and considering the proportion of the distribution above zero. Some participants adapted their strategies based on feedback, while others resorted to random guessing when they performed poorly."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Did not provide explicit incentive structures or uncertainty visualizations.",
                "This study": "Implemented an incentive structure to reward cautious decision-making and used various designs for communicating uncertainty."
            },
            {
                "Previous studies": "Did not use specific uncertainty visualization techniques.",
                "This study": "Used 50% confidence intervals and probability density functions to visualize uncertainty."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Implemented an incentive structure to reward cautious decision-making and used various designs for communicating uncertainty.",
                "Result": "Participants in the CI and PDF conditions made fewer false positives than the uncorrected benchmark but more than the Benjamini-Hochberg benchmark."
            },
            {
                "Innovation": "Used 50% confidence intervals and probability density functions to visualize uncertainty.",
                "Result": "The average false discovery rate was 34% in the PDF condition and 39% in the CI condition."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Primary care providers",
        "Tasks": "Assessing and improving patient-provider communication",
        "Application Scenarios": "Clinical visits between primary care providers and patients"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Relational communication theory & Roter Interaction Analysis System (RIAS)",
            "Function": "Automate the assessment of patient-provider communication using social signals",
            "Embedded knowledge": {
                "Architecture or framework": "1. Machine-learning pipeline for tracking social signals. 2. Web-application for visualizing communication patterns.",
                "Tool or tool kits": "1. ConverSense web-application for providers. 2. Social Signal Processing (SSP) pipeline."
            },
            "Implementation": "Audio-stream processing--Machine learning pipeline; Visualization--ConverSense web-application"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Conversational analysis & Social Signal Processing (SSP)",
            "Function": "Provide feedback on communication challenges during patient-provider interactions",
            "Embedded knowledge": {
                "Input or control techniques": "1. Ingest audio-streams of conversations. 2. Track the magnitude of social signals: dominance, interactivity, engagement, and warmth.",
                "Output or feedback methods": "1. Visualize communication patterns within and across visits. 2. Provide feedback on social signals through a web-based tool."
            },
            "Implementation": "Audio input--Machine learning pipeline; Feedback visualization--ConverSense web-application"
        }
    ],
    "Results": {
        "Performance": "The study demonstrated that ConverSense can provide valuable feedback on communication challenges. The system showed a mean normalized accuracy per visit of 0.94 for dominance, 0.77 for interactiveness, 0.89 for engagement, and 0.95 for warmth.",
        "User feedback": "Participants found the tool useful for self-reflection and appreciated the data-driven approach. However, they expressed the need for more contextualized and actionable feedback, and some found the absolute affect scores difficult to interpret."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Manual coding of patient-provider interactions using RIAS.",
                "This study": "Automated assessment of patient-provider communication using a machine-learning pipeline and visualization through a web-application."
            },
            {
                "Previous studies": "Feedback systems focusing on non-verbal cues without socioemotional context.",
                "This study": "Integration of social signals (dominance, interactivity, engagement, warmth) to provide a more nuanced understanding of communication patterns."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Automated assessment of patient-provider communication using a machine-learning pipeline and visualization through a web-application.",
                "Result": "The study demonstrated that ConverSense can provide valuable feedback on communication challenges. The system showed a mean normalized accuracy per visit of 0.94 for dominance, 0.77 for interactiveness, 0.89 for engagement, and 0.95 for warmth."
            },
            {
                "Innovation": "Integration of social signals (dominance, interactivity, engagement, warmth) to provide a more nuanced understanding of communication patterns.",
                "Result": "Participants found the tool useful for self-reflection and appreciated the data-driven approach. However, they expressed the need for more contextualized and actionable feedback, and some found the absolute affect scores difficult to interpret."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Policymakers, driver-organizers, litigators, and other stakeholders involved in rideshare gig work",
        "Tasks": "Using data probes to understand the impact of technology practices on workers, assist stakeholder interactions, demystify technology for policymakers, and support worker collective action",
        "Application Scenarios": "Policymaking processes, stakeholder interactions, driver education, and collective action efforts in the rideshare gig work sector"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Worker-centered data visualization techniques",
            "Function": "Assist stakeholder interactions, demystify technology for policymakers, and support worker collective action",
            "Embedded knowledge": {
                "Architecture or framework": [
                    "1. Data probes as boundary objects to facilitate stakeholder communication",
                    "2. Interactive visualizations to show the impact of technology behaviors on workers"
                ],
                "Tool or tool kits": [
                    "1. Work Planner: An AI work planning prototype to simulate inputs and outputs for drivers",
                    "2. Questimator: A tool to predict the estimated time commitment and financial implications of completing different Quests"
                ]
            },
            "Implementation": "Data visualization--Tableau; Data analysis--Python"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Human-centered computing and data visualization principles",
            "Function": "Help policymakers and other stakeholders understand the impact of technology practices on workers",
            "Embedded knowledge": {
                "Input or control techniques": [
                    "1. Interactive selection of work hours and locations",
                    "2. Inputting specific expenses and car ownership situations"
                ],
                "Output or feedback methods": [
                    "1. Visualization of net earnings after expenses",
                    "2. Estimation of hours required to complete Quests"
                ]
            },
            "Implementation": "Interactive data visualization--Tableau; Data analysis--Python"
        }
    ],
    "Results": {
        "Performance": "Data probes effectively illustrated the impact of technology practices on workers, helping stakeholders understand worker experiences and wage calculations. They also supported stakeholder interactions and policymaking processes by providing clear visualizations and estimations.",
        "User feedback": "Participants appreciated the clarity and utility of data probes in illustrating worker experiences and wage calculations. They found the tools valuable for educating policymakers, supporting driver education, and assisting in collective action efforts."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Traditional methods of presenting worker experiences and wage calculations",
                "This study": "Interactive data probes providing clear visualizations and estimations to illustrate the impact of technology practices on workers"
            },
            {
                "Previous studies": "Limited tools for simulating work inputs and outputs for gig workers",
                "This study": "Work Planner and Questimator to simulate work inputs, outputs, and financial implications for rideshare drivers"
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Interactive data probes providing clear visualizations and estimations to illustrate the impact of technology practices on workers",
                "Result": "Data probes effectively illustrated the impact of technology practices on workers, helping stakeholders understand worker experiences and wage calculations. They also supported stakeholder interactions and policymaking processes by providing clear visualizations and estimations."
            },
            {
                "Innovation": "Work Planner and Questimator to simulate work inputs, outputs, and financial implications for rideshare drivers",
                "Result": "Participants appreciated the clarity and utility of data probes in illustrating worker experiences and wage calculations. They found the tools valuable for educating policymakers, supporting driver education, and assisting in collective action efforts."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Scientists studying deep ocean microbial ecosystems",
        "Tasks": "Visualizing spatial trends, integrating data at multiple scales, maximizing the scientific value of limited sampling",
        "Application Scenarios": "Pre-cruise planning, on-the-fly decision-making during research expeditions"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Human-centered design methodology, Value-Suppressing Uncertainty Palettes (VSUPs)",
            "Function": "Enable scientists to explore previous sediment sampling history and decide where new samples may yield the greatest scientific return",
            "Embedded knowledge": {
                "Architecture or framework": "1. Interactive data workspace integrating 2D and 3D visualizations. 2. Real-time interpolation of biogeochemical and microbial processes.",
                "Tool or tool kits": "1. DeepSee, an open-source interactive workspace. 2. Electron.js for creating a portable web browser environment."
            },
            "Implementation": "UI framework and styling--Vue.js; Plotting cores and drawing bar charts--D3.js; Interpolations--SciPy and Python; 3D render scene--Three.js"
        }
    ],
    "Results": {
        "Performance": "DeepSee helped scientists organize collected sample data, familiarize themselves with new sites, examine sample data, correlate geochemical trends with microbial data, and identify sites of interest for future sampling.",
        "User feedback": "Scientists appreciated the integration of multiple data types, the ability to visualize data in a single interface, and the predictive capabilities of the Interpolation View. They found it useful for pre-cruise planning and as a repository of information for new researchers."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Existing tools like ArcGIS provide state-of-the-art capabilities for lab-based geo-spatiotemporal data analysis but lack support for rapid data integration and visualization of point-based field sample data interpolations in 3D.",
                "This study": "DeepSee bridges this gap by combining on-the-fly 3D data interpolation capabilities with fluid interactions across side-by-side 2D and 3D views of the data."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "DeepSee bridges the gap by combining on-the-fly 3D data interpolation capabilities with fluid interactions across side-by-side 2D and 3D views of the data.",
                "Result": "DeepSee helped scientists organize collected sample data, familiarize themselves with new sites, examine sample data, correlate geochemical trends with microbial data, and identify sites of interest for future sampling."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "None",
        "Tasks": "None",
        "Application Scenarios": "None"
    },
    "Contributions": [],
    "Results": {
        "Performance": "None",
        "User feedback": "None"
    },
    "Second Extraction": {
        "Innovations": [],
        "Quadruple": []
    }
}
{
    "Target Definition": {
        "Target User Group": "Community members, disability advocates, and local government officials",
        "Tasks": "Conducting sidewalk accessibility assessments, mapping, analyzing, and presenting collected data",
        "Application scenarios": "Community-driven sidewalk audits and advocacy for urban accessibility improvements"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Community science and digital civics",
            "Function": "Facilitate community-driven sidewalk accessibility assessments and advocacy",
            "Embedded knowledge": {
                "Architecture or framework": "1. Open-source crowdsourcing platform for sidewalk accessibility data collection. 2. Interactive analytic tools for data visualization and validation.",
                "Tool or tool kits": "1. Project Sidewalk platform for remote sidewalk labeling and validation. 2. Built-in analytic tools like LabelMap and Gallery for data visualization."
            },
            "Implementation": "Sidewalk labeling and validation--Project Sidewalk; Data visualization--LabelMap & Gallery"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Crowdsourcing and gamification",
            "Function": "Engage community members in sidewalk accessibility assessments",
            "Embedded knowledge": {
                "Input or control techniques": "1. Remote labeling of sidewalk features and barriers using street view imagery. 2. Validation of previously labeled images by other users.",
                "Output or feedback methods": "1. Real-time statistics on labeling performance and accuracy. 2. Leaderboard and performance badges to motivate contributions."
            },
            "Implementation": "Labeling and validation--Project Sidewalk; Performance tracking--Leaderboard & badges"
        }
    ],
    "Results": {
        "Performance": "The project successfully engaged 81 volunteers who contributed 12,191 labels and 19,396 validations with an accuracy rate of 93.1%. The data covered 35.9 miles of streets, with 58.38% of streets receiving multiple audits.",
        "User feedback": "Participants reported increased awareness of urban accessibility issues and a sense of empowerment. The Scouts developed civic skills and public speaking abilities, and community members appreciated the scalability and remote participation features of Project Sidewalk."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Traditional in-person sidewalk audits and citizen call-in reports",
                "This study": "Remote, scalable, and interactive crowdsourcing platform for sidewalk accessibility assessments using Project Sidewalk"
            },
            {
                "Previous studies": "Limited engagement and motivation in community science projects",
                "This study": "Gamification elements like real-time statistics, leaderboards, and performance badges to sustain engagement and motivate contributions"
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Remote, scalable, and interactive crowdsourcing platform for sidewalk accessibility assessments using Project Sidewalk",
                "Result": "The project successfully engaged 81 volunteers who contributed 12,191 labels and 19,396 validations with an accuracy rate of 93.1%. The data covered 35.9 miles of streets, with 58.38% of streets receiving multiple audits."
            },
            {
                "Innovation": "Gamification elements like real-time statistics, leaderboards, and performance badges to sustain engagement and motivate contributions",
                "Result": "Participants reported increased awareness of urban accessibility issues and a sense of empowerment. The Scouts developed civic skills and public speaking abilities, and community members appreciated the scalability and remote participation features of Project Sidewalk."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Users in virtual reality environments",
        "Tasks": "Providing kinesthetic force feedback to the lower body",
        "Application Scenarios": "Virtual reality gaming environments, rehabilitation training, and immersive simulations"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Biomechanical simulation, Electrical Muscle Stimulation (EMS)",
            "Function": "Provide precise large-scale kinesthetic force feedback to the lower body",
            "Embedded knowledge": {
                "Architecture or framework": [
                    "Combining biomechanical simulation with EMS to calculate and deliver joint torque in real-time",
                    "Using OpenSim and Nvidia PhysX engine for biomechanical simulation"
                ],
                "Tool or tool kits": [
                    "TENS 7000 device for generating EMS signals",
                    "Perception Neuron Studio for motion capture",
                    "OpenGo plantar pressure sensor for ground reaction force measurement"
                ]
            },
            "Implementation": "Motion capture--Perception Neuron Studio; Ground reaction force measurement--OpenGo plantar pressure sensor; EMS signal generation--TENS 7000 device"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Biomechanical simulation, Electrical Muscle Stimulation (EMS)",
            "Function": "Provide haptic feedback to enhance user immersion and presence in VR environments",
            "Embedded knowledge": {
                "Input or control techniques": [
                    "Real-time calculation of joint torque using biomechanical simulation",
                    "Personalization of EMS intensity and location based on user-specific torque-intensity relationship"
                ],
                "Output or feedback methods": [
                    "Delivering force feedback through EMS to simulate virtual forces acting on the lower body"
                ]
            },
            "Implementation": "Haptic feedback--EMS; Biomechanical simulation--OpenSim and Nvidia PhysX engine"
        }
    ],
    "Results": {
        "Performance": "ErgoPulse significantly improved the accuracy of haptic force delivery in both continuous and impulse force environments, with Jaccard similarity scores indicating higher accuracy compared to traditional EMS methods.",
        "User feedback": "Users reported increased immersion and presence in VR environments with ErgoPulse, noting the realistic and enjoyable haptic feedback. Some users mentioned the need for additional stimuli such as temperature and skin stretch to further enhance realism."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Traditional EMS systems without biomechanical simulation",
                "This study": "Combines biomechanical simulation with EMS to provide precise and personalized haptic feedback to the lower body"
            },
            {
                "Previous studies": "Limited accuracy in haptic force delivery using traditional EMS",
                "This study": "Significantly improves the accuracy of haptic force delivery through real-time biomechanical simulation and personalized EMS intensity"
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Combines biomechanical simulation with EMS to provide precise and personalized haptic feedback to the lower body",
                "Result": "ErgoPulse significantly improved the accuracy of haptic force delivery in both continuous and impulse force environments, with Jaccard similarity scores indicating higher accuracy compared to traditional EMS methods."
            },
            {
                "Innovation": "Significantly improves the accuracy of haptic force delivery through real-time biomechanical simulation and personalized EMS intensity",
                "Result": "Users reported increased immersion and presence in VR environments with ErgoPulse, noting the realistic and enjoyable haptic feedback. Some users mentioned the need for additional stimuli such as temperature and skin stretch to further enhance realism."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Electronics designers with varying levels of expertise",
        "Tasks": "Designing and optimizing board-level circuits by exploring alternatives in component-based design",
        "Application scenarios": "Designing custom printed circuit boards (PCBs) for various electronic devices"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Type system of electronics parts, design space exploration (DSE)",
            "Function": "Help users understand and make design choices by sweeping the design space of alternatives for electronics parts",
            "Embedded knowledge": {
                "Architecture or framework": "1. Type system of electronics parts that implicitly defines a design space. 2. User-guided design space exploration tool that helps users understand and compare choices.",
                "Tool or tool kits": "1. Open-source HDL for PCB design. 2. Mixed textual/graphical block diagram IDE."
            },
            "Implementation": "Design space sweep--User-defined design space and objective functions; Visualization--Scatter plots and parallel coordinate plots; Compilation--Partial compilation and state copying"
        }
    ],
    "Results": {
        "Performance": "The system helps users understand and make design choices by sweeping the design space of alternatives for electronics parts, marking invalid options, and plotting points to visualize trade-offs. Participants were able to use DSE to find viable and optimized designs among alternatives.",
        "User feedback": "Participants found the system useful for both novices and experts. Novices appreciated the validity indicators and integrated component data, while experts valued the ability to optimize designs and assess trade-offs. Some participants suggested improvements in the user interface for better discoverability of parameters and objective functions."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Highly automated tools for novices or highly manual tools for experts",
                "This study": "User-guided design space exploration tool that bridges the gap between high-level representation and fully-specified, fabrication-ready circuits"
            },
            {
                "Previous studies": "Limited support for understanding and comparing design choices",
                "This study": "Visualization of design space and trade-offs using scatter plots and parallel coordinate plots"
            }
        ],
        "Quadruple": [
            {
                "Innovation": "User-guided design space exploration tool that bridges the gap between high-level representation and fully-specified, fabrication-ready circuits",
                "Result": "Participants were able to use DSE to find viable and optimized designs among alternatives."
            },
            {
                "Innovation": "Visualization of design space and trade-offs using scatter plots and parallel coordinate plots",
                "Result": "Participants found the system useful for both novices and experts. Novices appreciated the validity indicators and integrated component data, while experts valued the ability to optimize designs and assess trade-offs."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Industrial designers and makers",
        "Tasks": "Designing and building interactive artifacts using e-acrylic",
        "Application scenarios": "Rapid prototyping of interactive product prototypes, building physical interactive systems"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Acrylic making practices, physical computing practices",
            "Function": "Enable industrial designers to integrate electronics into acrylic sheets for interactive artifacts",
            "Embedded knowledge": {
                "Architecture or framework": "1. Systematic approach to embed electronic circuits into acrylic sheets using laser cutting and conductive paint. 2. Methods to shape e-acrylic into 3D objects through thermoforming and joinery.",
                "Tool or tool kits": "1. Laser engraving and cutting for circuit traces and physical features. 2. Manual painting of conductive ink into engraved traces. 3. Techniques for mounting electronic components onto e-acrylic."
            },
            "Implementation": "Laser engraving--Epilog Helix 30W; Conductive paint application--MG Chemicals 842AR; Thermoforming--Carbon fiber heater, oven"
        },
        {
            "Innovation type": "Design",
            "Supporting knowledge": "Acrylic making practices, physical computing practices",
            "Function": "Create interactive artifacts that integrate electronic circuits within acrylic structures",
            "Embedded knowledge": {
                "Prototype, script or models": "1. Game controller with embedded touch buttons and LEDs. 2. Mesh lamp with integrated LEDs. 3. Water level vase with water detection and LED indicators. 4. Pinball machine with compliant structures and embedded circuits. 5. Cup warmer with heating element and compliant structure. 6. Interactive contour map with touchscreen extension.",
                "Material or crafts": "1. Use of transparent and opaque acrylic sheets. 2. Techniques for embedding conductive traces and electronic components into acrylic. 3. Methods for shaping acrylic into 3D forms and assemblies."
            },
            "Implementation": "Laser cutting--Epilog Helix 30W; Conductive paint--MG Chemicals 842AR; Thermoforming--Carbon fiber heater, oven; Assembly--Acrylic cement, bolts and nuts"
        }
    ],
    "Results": {
        "Performance": "The study demonstrated the feasibility of embedding electronic circuits into acrylic sheets and shaping them into interactive artifacts. The e-acrylic approach enabled the creation of various functional prototypes, including a game controller, mesh lamp, water level vase, pinball machine, cup warmer, and interactive contour map.",
        "User feedback": "Users found the e-acrylic approach to be effective for rapid prototyping and appreciated the integration of electronics into the acrylic material. The transparent and visible circuits added to the aesthetic appeal of the artifacts. The conductive joints and thermoforming techniques were particularly noted for their utility in creating complex interactive systems."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Acrylic sheets used primarily as physical structures for enclosing electronics",
                "This study": "Developed e-acrylic as an electronic composite that embeds circuits into acrylic sheets, enabling new forms of interactive artifacts"
            },
            {
                "Previous studies": "Separate processes for shaping acrylic and integrating electronics",
                "This study": "Integrated electronic circuit fabrication with acrylic shaping techniques, such as laser cutting, thermoforming, and joinery"
            },
            {
                "Previous studies": "Limited use of conductive paint for creating circuits on acrylic",
                "This study": "Systematically used conductive paint to create double-layer circuits and connect circuits across joints in acrylic assemblies"
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Developed e-acrylic as an electronic composite that embeds circuits into acrylic sheets, enabling new forms of interactive artifacts",
                "Result": "The study demonstrated the feasibility of embedding electronic circuits into acrylic sheets and shaping them into interactive artifacts."
            },
            {
                "Innovation": "Integrated electronic circuit fabrication with acrylic shaping techniques, such as laser cutting, thermoforming, and joinery",
                "Result": "The e-acrylic approach enabled the creation of various functional prototypes, including a game controller, mesh lamp, water level vase, pinball machine, cup warmer, and interactive contour map."
            },
            {
                "Innovation": "Systematically used conductive paint to create double-layer circuits and connect circuits across joints in acrylic assemblies",
                "Result": "Users found the e-acrylic approach to be effective for rapid prototyping and appreciated the integration of electronics into the acrylic material."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Radiologists and clinicians",
        "Tasks": "Identifying and designing clinically relevant vision-language applications for radiology",
        "Application scenarios": "Radiology imaging workflows involving referring clinicians and radiologists"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Human-centered AI, Interaction design process and methods",
            "Function": "Enhance radiology imaging workflows for radiologists and clinicians",
            "Embedded knowledge": {
                "Architecture or framework": "1. Iterative, multidisciplinary design process for envisioning clinically relevant VLM interactions. 2. Co-designed four VLM use concepts: Draft Report Generation, Augmented Report Review, Visual Search and Querying, and Patient Imaging History Highlights.",
                "Tool or tool kits": "1. Click-through Figma prototypes for design concepts. 2. Use of MIMIC-CXR X-ray dataset for populating prototypes."
            },
            "Implementation": "Prototyping--Figma; Dataset--MIMIC-CXR"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Human-centered AI, Interaction design process and methods",
            "Function": "Assist radiologists and clinicians in interpreting and reporting medical images",
            "Embedded knowledge": {
                "Input or control techniques": "1. Visual selection tool for image search or image and text queries. 2. AI assistant feature for contextual queries.",
                "Output or feedback methods": "1. Report overview feature highlighting abnormal findings. 2. AI-generated summary of prior images and/or reports."
            },
            "Implementation": "Image search--Hospital database; Querying--AI assistant"
        },
        {
            "Innovation type": "Design",
            "Supporting knowledge": "Human-centered AI, Interaction design process and methods",
            "Function": "Provide innovative design concepts for VLM-assisted radiology workflows",
            "Embedded knowledge": {
                "Prototype, script or models": "1. Draft Report Generation concept with AI-generated report in bullet point form. 2. Augmented Report Review concept with report overview and AI assistant features. 3. Visual Search and Querying concept with visual selection tool. 4. Patient Imaging History Highlights concept with AI-generated summary.",
                "Material or crafts": "1. Click-through Figma prototypes. 2. Use of open source MIMIC-CXR X-ray dataset."
            },
            "Implementation": "Prototyping--Figma; Dataset--MIMIC-CXR"
        }
    ],
    "Results": {
        "Performance": "Participants perceived the VLM concepts as valuable, with expectations of near-perfect AI performance for draft report generation, and utility in visual search and querying, and patient imaging history highlights.",
        "User feedback": "Radiologists and clinicians highlighted the need for time savings, reduced cognitive burden, and accurate, structured reporting. They preferred tool-based interactions over chatbots and emphasized the importance of context-specific information."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Focus on technical proof-of-concepts and lab experiments",
                "This study": "Adoption of human-centered, participatory approaches to design clinically relevant VLM interactions"
            },
            {
                "Previous studies": "Use of AI for diagnostic outputs and explanations",
                "This study": "Exploration of VLM capabilities for draft report generation, visual search and querying, and patient imaging history highlights"
            },
            {
                "Previous studies": "Limited stakeholder engagement in early AI design stages",
                "This study": "Iterative design process involving radiologists and clinicians to co-create VLM use concepts"
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Adoption of human-centered, participatory approaches to design clinically relevant VLM interactions",
                "Result": "Participants perceived the VLM concepts as valuable, with expectations of near-perfect AI performance for draft report generation, and utility in visual search and querying, and patient imaging history highlights."
            },
            {
                "Innovation": "Exploration of VLM capabilities for draft report generation, visual search and querying, and patient imaging history highlights",
                "Result": "Radiologists and clinicians highlighted the need for time savings, reduced cognitive burden, and accurate, structured reporting. They preferred tool-based interactions over chatbots and emphasized the importance of context-specific information."
            },
            {
                "Innovation": "Iterative design process involving radiologists and clinicians to co-create VLM use concepts",
                "Result": "Participants perceived the VLM concepts as valuable, with expectations of near-perfect AI performance for draft report generation, and utility in visual search and querying, and patient imaging history highlights."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Cyclists",
        "Tasks": "Interactions between cyclists and autonomous vehicles using external Human-Machine Interfaces (eHMIs)",
        "Application scenarios": "Various traffic scenarios including intersections, roundabouts, lane merging, and bottlenecks"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "User-centered design principles & iterative design approach",
            "Function": "Enable safe interactions between cyclists and autonomous vehicles by replacing driver social signals with eHMIs",
            "Embedded knowledge": {
                "Architecture or framework": "1. Iterative design approach for eHMIs based on cyclist feedback. 2. Use of VR cycling simulator and real-world Wizard-of-Oz study to evaluate eHMI designs.",
                "Tool or tool kits": "1. VR cycling simulator for initial eHMI evaluation. 2. Real-world implementation of eHMIs on a moving car for practical evaluation."
            },
            "Implementation": "VR cycling simulator--Unity3D; Real-world eHMI control--LED strips and matrix controlled via Bluetooth"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Human-centered computing & HCI design and evaluation methods",
            "Function": "Communicate AV intent and awareness to cyclists using visual signals",
            "Embedded knowledge": {
                "Input or control techniques": "1. Use of LED strips and matrix to display color-coded signals. 2. Control of eHMI states via Bluetooth based on cyclist proximity.",
                "Output or feedback methods": "1. Red/green color signals to indicate AV yielding or not yielding. 2. Animations to reinforce color changes for better visibility."
            },
            "Implementation": "VR cycling simulator--Unity3D; Real-world eHMI control--LED strips and matrix controlled via Bluetooth"
        }
    ],
    "Results": {
        "Performance": "The study found that cyclists preferred eHMIs using red/green signals to communicate AV intent, with Safe Zone and LightRing being the most effective. Cyclists were more confident in AV awareness and intent, performed fewer shoulder checks, and rode at higher speeds with eHMIs.",
        "User feedback": "Cyclists provided positive feedback on eHMIs using large surfaces and simple color-coded signals. Safe Zone and LightRing were particularly well-received for their visibility and ease of understanding. Emoji-Car was less preferred due to its complexity and placement on the roof."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Previous studies focused on pedestrian-AV interactions and used single-color signals with animations.",
                "This study": "This study introduced versatile eHMIs for cyclists using red/green signals and large surfaces on the AV body, evaluated through both VR and real-world settings."
            },
            {
                "Previous studies": "Previous studies used static evaluations or single-scenario tests for eHMIs.",
                "This study": "This study conducted a two-stage evaluation, first in a VR simulator and then in a real-world Wizard-of-Oz study, covering multiple traffic scenarios."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Versatile eHMIs using red/green signals and large surfaces on the AV body.",
                "Result": "Cyclists were more confident in AV awareness and intent, performed fewer shoulder checks, and rode at higher speeds with these eHMIs."
            },
            {
                "Innovation": "Two-stage evaluation covering multiple traffic scenarios.",
                "Result": "Safe Zone and LightRing were particularly well-received for their visibility and ease of understanding, while Emoji-Car was less preferred due to its complexity and placement on the roof."
            }
        ]
    }
}

{
    "Target Definition": {
        "Target User Group": "Engineers and designers working on robot voice customization",
        "Tasks": "Creating and matching robot voices to robot appearances",
        "Application scenarios": "Human-robot interaction in various domains such as healthcare, customer service, and personal assistants"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Gibbs Sampling with People (GSP), Sequential Transmission Evaluation Pipeline (STEP-Tag)",
            "Function": "Create and match robot voices to robot appearances",
            "Embedded knowledge": {
                "Architecture or framework": [
                    "1. Adaptive human-in-the-loop pipeline for tuning robotic voices",
                    "2. Taxonomy elicitation procedure for identifying relevant attributes",
                    "3. Web interface for customizing robot voices"
                ],
                "Tool or tool kits": [
                    "1. Voice creation tool combining TTS and traditional signal processing techniques",
                    "2. Online robot voice prediction tool"
                ]
            },
            "Implementation": "Voice synthesis--VITS; Voice manipulation--Librosa; Voice effects--Parselmouth, TAL Vocoder, Pedalboard"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Human-in-the-loop sampling, human-in-the-loop labeling",
            "Function": "Efficiently search and find the best matching voice for a robot",
            "Embedded knowledge": {
                "Input or control techniques": [
                    "1. Participants change the voice of the robot using sliders",
                    "2. Participants rate the relevance of tags describing their impression of the robot"
                ],
                "Output or feedback methods": [
                    "1. Iteratively improved voice match ratings",
                    "2. Elicited taxonomy used to predict suitable voices for new robots"
                ]
            },
            "Implementation": "Voice matching--Gibbs Sampling with People (GSP); Labeling--Sequential Transmission Evaluation Pipeline (STEP-Tag)"
        }
    ],
    "Results": {
        "Performance": "The study demonstrated that participants could efficiently match voices to robots, with ratings improving over iterations. The final voices were significantly better matched than random voices, with a mean rating of 3.4 out of 5.",
        "User feedback": "Participants found the voice creation tool effective and the iterative process led to improved voice matches. The predicted voices for new robots were rated similarly to the matched voices, confirming the robustness of the approach."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Limited number of robots and voice dimensions explored",
                "This study": "Large-scale behavioral experiments with 175 robots and a wide range of voice dimensions"
            },
            {
                "Previous studies": "Fixed voice samples",
                "This study": "Adaptive human-in-the-loop pipeline for tuning robotic voices"
            },
            {
                "Previous studies": "Predefined taxonomies",
                "This study": "Open-ended labeling using STEP-Tag to elicit relevant attributes"
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Large-scale behavioral experiments with 175 robots and a wide range of voice dimensions",
                "Result": "Participants could efficiently match voices to robots, with ratings improving over iterations."
            },
            {
                "Innovation": "Adaptive human-in-the-loop pipeline for tuning robotic voices",
                "Result": "The final voices were significantly better matched than random voices, with a mean rating of 3.4 out of 5."
            },
            {
                "Innovation": "Open-ended labeling using STEP-Tag to elicit relevant attributes",
                "Result": "The predicted voices for new robots were rated similarly to the matched voices, confirming the robustness of the approach."
            }
        ]
    }
}

{
    "Target Definition": {
        "Target User Group": "CS researchers in various computer science disciplines",
        "Tasks": "Exploring and listing undesirable consequences of digital technologies",
        "Application Scenarios": "Using an interactive, web-based interface to view, sort, and save summaries of undesirable consequences"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "NLP techniques",
            "Function": "Extract real-world undesirable consequences of technology from online articles, summarize and categorize them, and present them in an interactive, web-based interface",
            "Embedded knowledge": {
                "Architecture or framework": "1. Information distillation pipeline leveraging NLP techniques for self-updating catalog of undesirable consequences. 2. Categorization based on the aspect of life affected (e.g., health, equality, politics).",
                "Tool or tool kits": "1. RoBERTA-based supervised binary classifier for article filtering. 2. GPT-3.5 for content summarization and aspect categorization."
            },
            "Implementation": "Article retrieval--Selenium & Beautifulsoup; Article content extraction--newspaper3k API; Summarization and categorization--GPT-3.5"
        }
    ],
    "Results": {
        "Performance": "Blip supported participants in discovering more and more diverse undesirable consequences beyond their prior knowledge and online search. Participants listed an average of 7.00 additional consequences using Blip.",
        "User feedback": "Participants found Blip engaging and useful for learning about undesirable consequences and reflecting on their own experiences. They appreciated the summaries and aspect categories, and suggested it could be useful for brainstorming, writing ethics statements, and for various stakeholders."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Relying on prior knowledge and online search for discovering undesirable consequences.",
                "This study": "Blip provides an automated, interactive system that extracts, summarizes, and categorizes undesirable consequences from online articles, significantly increasing the number and diversity of consequences discovered."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Blip provides an automated, interactive system that extracts, summarizes, and categorizes undesirable consequences from online articles, significantly increasing the number and diversity of consequences discovered.",
                "Result": "Blip supported participants in discovering more and more diverse undesirable consequences beyond their prior knowledge and online search. Participants listed an average of 7.00 additional consequences using Blip."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "General users interested in interactive shape displays",
        "Tasks": "Drawing and interacting with magnetic patterns on a pin-based shape display",
        "Application Scenarios": "Interactive storytelling, shape doodling, and shape drawing games"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Magnetic materials and high-density pin arrays",
            "Function": "Provide an interactive shape display with low cost and high interactivity",
            "Embedded knowledge": {
                "Architecture or frame work": [
                    "High-density magnetic pin array",
                    "Magnetic belt conveyor system"
                ],
                "Tool or tool kits": [
                    "Magnetic drawing tools",
                    "Magnetic eraser tool",
                    "Stripe tool with multiple magnets"
                ]
            },
            "Implementation": "Magnetic belt conveyor--Dobot mini conveyor belt; Control unit--Dobot magic box; Sensor module kit--M5Stack; Visual programming tool--Scratch"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Magnetic materials and high-density pin arrays",
            "Function": "Enable users to interactively draw and display shapes using magnetic patterns",
            "Embedded knowledge": {
                "Input or control techniques": [
                    "Hand-drawn magnetic patterns using a magnetizing stylus",
                    "Magnetic stripe tool for drawing patterns"
                ],
                "Output or feedback methods": [
                    "Display shapes on a high-density pin array",
                    "Dynamic levitation of pins based on magnetic patterns"
                ]
            },
            "Implementation": "Drawing magnetic patterns--Hand-drawn; Display shapes--High-density pin array"
        },
        {
            "Innovation type": "Design",
            "Supporting knowledge": "Magnetic materials and high-density pin arrays",
            "Function": "Create interactive and engaging applications using a pin-based shape display",
            "Embedded knowledge": {
                "Prototype, script or models": [
                    "Shape doodler",
                    "Interactive storytelling tool",
                    "Shape drawing games"
                ],
                "Material or crafts": [
                    "Polystyrene foam for pin bodies",
                    "Magnetic disks for pin levitation"
                ]
            },
            "Implementation": "Pin body--Polystyrene foam; Magnetic disks--3 mm diameter; Grid frame--6.3 mm pitch"
        }
    ],
    "Results": {
        "Performance": "The system effectively displays shapes based on hand-drawn magnetic patterns with a high degree of interactivity. The optimal speed for dynamic pin levitation is between 80 and 100 mm/sec, achieving a maximum levitation height of nearly 12 mm.",
        "User feedback": "Users found the system engaging and easy to use, appreciating the low cost and simplicity. The ability to quickly draw and erase patterns was highlighted as a significant advantage. However, some limitations were noted in displaying large solid shapes."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "MagneShape used magnetic forces for pin levitation but had limited interactivity and required precise magnetic patterns.",
                "This study": "MagneSwift improved interactivity with a high-density pin array and a magnetic belt conveyor system, allowing for dynamic shape presentation based on hand-drawn patterns."
            },
            {
                "Previous studies": "Pin-based shape displays often required numerous actuators and complex setups.",
                "This study": "MagneSwift reduced complexity and cost by using magnetic materials and a simple conveyor system, making the technology more accessible."
            },
            {
                "Previous studies": "Shape displays were typically static or required complex electronic components for dynamic interaction.",
                "This study": "MagneSwift achieved dynamic interaction with minimal electronic components, leveraging the properties of magnetic materials for interactive applications."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "MagneSwift improved interactivity with a high-density pin array and a magnetic belt conveyor system, allowing for dynamic shape presentation based on hand-drawn patterns.",
                "Result": "The system effectively displays shapes based on hand-drawn magnetic patterns with a high degree of interactivity. The optimal speed for dynamic pin levitation is between 80 and 100 mm/sec, achieving a maximum levitation height of nearly 12 mm."
            },
            {
                "Innovation": "MagneSwift reduced complexity and cost by using magnetic materials and a simple conveyor system, making the technology more accessible.",
                "Result": "Users found the system engaging and easy to use, appreciating the low cost and simplicity. The ability to quickly draw and erase patterns was highlighted as a significant advantage. However, some limitations were noted in displaying large solid shapes."
            },
            {
                "Innovation": "MagneSwift achieved dynamic interaction with minimal electronic components, leveraging the properties of magnetic materials for interactive applications.",
                "Result": "The system effectively displays shapes based on hand-drawn magnetic patterns with a high degree of interactivity. The optimal speed for dynamic pin levitation is between 80 and 100 mm/sec, achieving a maximum levitation height of nearly 12 mm."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Users engaged in multitasking scenarios",
        "Tasks": "Task switching in a dual-task balancing game",
        "Application scenarios": "Fast-paced, visual-motoric, and continuous multitasking situations such as driving or remote control of multiple vehicles/drones"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Computational Rationality & Reinforcement Learning",
            "Function": "Improve human performance in multitasking by managing task switches",
            "Embedded knowledge": {
                "Architecture or framework": "1. Reinforcement Learning (RL) based attention management system (AMS) 2. Cognitive model with human constraints for training the AMS",
                "Tool or tool kits": "1. Unity for game implementation 2. ml-agents library for training RL agents"
            },
            "Implementation": "Game implementation--Unity; Training RL agents--ml-agents library"
        }
    ],
    "Results": {
        "Performance": "Participants using the AMS trained on the cognitive model achieved significantly higher performance (average game score of 36.29s) compared to the no supervisor condition (25.99s) and other conditions. The AMS trained on the cognitive model improved performance by 1.5 times on average.",
        "User feedback": "Participants rated the AMS trained on the cognitive model as having lower mental and physical demand, effort, and frustration compared to the no supervisor and notification conditions. The cognitive model condition was rated similarly in overall experience to the no supervisor condition."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Existing AMSs are based on theories or data-driven approaches requiring expert knowledge or large labeled datasets.",
                "This study": "Proposes an RL-based AMS trained with a cognitive model incorporating human constraints, improving multitasking performance without extensive task-specific data."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Proposes an RL-based AMS trained with a cognitive model incorporating human constraints, improving multitasking performance without extensive task-specific data.",
                "Result": "Participants using the AMS trained on the cognitive model achieved significantly higher performance (average game score of 36.29s) compared to the no supervisor condition (25.99s) and other conditions. The AMS trained on the cognitive model improved performance by 1.5 times on average."
            }
        ]
    }
}

{
    "Target Definition": {
        "Target User Group": "Users of wrist-based input devices",
        "Tasks": "Rapid online parametric optimization for wrist-based interactions",
        "Application Scenarios": "Personalized calibration of wrist-based pointing devices in AR interfaces"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Bayesian optimization, meta-learning",
            "Function": "Rapidly determine user-specific optimal settings for wrist-based pointing",
            "Embedded knowledge": {
                "Architecture or framework": [
                    "1. Meta-Bayesian optimization (meta-BO) method incorporating meta-learning of prior optimization data from a user population.",
                    "2. Transfer Acquisition Function+ (TAF+) extending TAF for parametric optimization by enabling designer control of weighting multiple objectives and tuning the importance between prior population and current real-time user’s data."
                ],
                "Tool or tool kits": [
                    "1. TAF+ algorithm for online, sample-efficient parametric optimization."
                ]
            },
            "Implementation": "Multi-objective optimization--BoTorch; Gaussian Process regression--BoTorch; Population modeling--BoTorch"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Bayesian optimization, meta-learning",
            "Function": "Improve user performance in wrist-based pointing by optimizing interaction parameters",
            "Embedded knowledge": {
                "Input or control techniques": [
                    "1. Incorporate meta-learning of prior optimization data from a user population with Bayesian optimization.",
                    "2. Use Transfer Acquisition Function+ (TAF+) to dynamically adjust objective weights and decay hyperparameters for rapid adaptation."
                ],
                "Output or feedback methods": [
                    "1. Provide real-time feedback on the optimal parameter settings based on user performance metrics."
                ]
            },
            "Implementation": "Wrist-based pointing--IMU and IR sensors; Real-time feedback--BoTorch"
        }
    ],
    "Results": {
        "Performance": "Meta-BO improves absolute pointing performance by 22.92% and 21.35% compared to BO and manual calibration, respectively. It also improves relative pointing performance by 25.43% and 13.60%.",
        "User feedback": "Users found meta-BO to be less frustrating and more efficient compared to manual calibration. Meta-BO led to significantly lower frustration levels and comparable or better user experience."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Traditional human-in-the-loop Bayesian optimization methods require many iterations and long durations to converge.",
                "This study": "Meta-BO with TAF+ enables rapid calibration of parameters for new users with a handful of trials by leveraging prior optimization data from a user population."
            },
            {
                "Previous studies": "Manual calibration processes are time-consuming and do not guarantee optimal outcomes.",
                "This study": "Meta-BO outperforms manual calibration by providing user-specific optimal settings more efficiently and effectively."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Meta-BO with TAF+ enables rapid calibration of parameters for new users with a handful of trials by leveraging prior optimization data from a user population.",
                "Result": "Meta-BO improves absolute pointing performance by 22.92% and 21.35% compared to BO and manual calibration, respectively. It also improves relative pointing performance by 25.43% and 13.60%."
            },
            {
                "Innovation": "Meta-BO outperforms manual calibration by providing user-specific optimal settings more efficiently and effectively.",
                "Result": "Users found meta-BO to be less frustrating and more efficient compared to manual calibration. Meta-BO led to significantly lower frustration levels and comparable or better user experience."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "None",
        "Tasks": "None",
        "Application scenarios": "None"
    },
    "Contributions": [],
    "Results": {
        "Performance": "None",
        "User feedback": "None"
    },
    "Second Extraction": {
        "Innovations": [],
        "Quadruple": []
    }
}

{
    "Target Definition": {
        "Target User Group": "Novices to design who may lack domain knowledge but still have unique requirements",
        "Tasks": "Customization of parametric designs for personal fabrication",
        "Application scenarios": "Designing everyday household artifacts like furniture and decorative items in their future usage context"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Parametric Design, Extended Reality",
            "Function": "Enable in-situ interaction with parametric designs for personal fabrication",
            "Embedded knowledge": {
                "Architecture or framework": [
                    "1. In-situ previewing and configuration of parametric designs using XR",
                    "2. Gesture-based measurement and ergonomic recommendations",
                    "3. Early, in-situ validation of designs through stability and lighting estimations"
                ],
                "Tool or tool kits": [
                    "1. pARam application for Microsoft HoloLens 2",
                    "2. Archimatix for authoring custom parametric models"
                ]
            },
            "Implementation": "Unity 3D 2021.2.15--Development environment; MRTK 2.7.3--Input and interactions; Archimatix--Parametric models"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Gesture-based input, Voice commands",
            "Function": "Support users in choosing valid and fitting parameters with respect to their unique physical contexts and requirements",
            "Embedded knowledge": {
                "Input or control techniques": [
                    "1. Gesture-based measurements using one-handed and two-handed gestures",
                    "2. Voice commands for capturing measurements"
                ],
                "Output or feedback methods": [
                    "1. Stability estimation through simulated drops",
                    "2. Lighting and shadowing estimation using custom shaders"
                ]
            },
            "Implementation": "Microsoft HoloLens 2--Platform for XR interactions"
        }
    ],
    "Results": {
        "Performance": "Participants successfully incorporated context into their design process, with comparable error rates between pARam and the desktop variant. pARam enabled more spatial and dynamic interactions, though it had higher physical demand and occasional precision issues.",
        "User feedback": "Participants appreciated the spatial and dynamic nature of pARam, finding it fun and helpful for iterating quickly. They valued the in-situ preview and validation features but noted issues with input handling and the limited field of view of the HoloLens."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Ex-situ interaction with parametric design configurators",
                "This study": "In-situ interaction with parametric designs using XR, enabling spatial, context-aware customization and validation"
            },
            {
                "Previous studies": "Traditional measurement tools and ex-situ design environments",
                "This study": "Gesture-based measurements and voice commands for direct input of dimensions, reducing error-prone transfers"
            },
            {
                "Previous studies": "Limited early validation of design consequences",
                "This study": "Early, in-situ validation of designs through stability and lighting estimations using XR capabilities"
            }
        ],
        "Quadruple": [
            {
                "Innovation": "In-situ interaction with parametric designs using XR, enabling spatial, context-aware customization and validation",
                "Result": "Participants successfully incorporated context into their design process, with comparable error rates between pARam and the desktop variant."
            },
            {
                "Innovation": "Gesture-based measurements and voice commands for direct input of dimensions, reducing error-prone transfers",
                "Result": "Participants appreciated the spatial and dynamic nature of pARam, finding it fun and helpful for iterating quickly."
            },
            {
                "Innovation": "Early, in-situ validation of designs through stability and lighting estimations using XR capabilities",
                "Result": "Participants valued the in-situ preview and validation features but noted issues with input handling and the limited field of view of the HoloLens."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "None",
        "Tasks": "None",
        "Application Scenarios": "None"
    },
    "Contributions": [],
    "Results": {
        "Performance": "None",
        "User feedback": "None"
    },
    "Second Extraction": {
        "Innovations": [],
        "Quadruple": []
    }
}
{
    "Target Definition": {
        "Target User Group": "Crowdworkers in crowdsourcing platforms",
        "Tasks": "Labeling urban accessibility issues",
        "Application scenarios": "Crowdsourced science platforms for urban accessibility"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Programmatic Weak Supervision (PWS) & FT-Transformers",
            "Function": "Provide just-in-time feedback during crowdsourced labeling to improve data quality and user expertise",
            "Embedded knowledge": {
                "Architecture or framework": "1. A novel ML-based pipeline for detecting labeling mistakes, trained on unannotated data with minimal expert-validated data. 2. A real-time system that tracks worker behavior and intervenes when an inferred mistake occurs.",
                "Tool or tool kits": "1. Snorkel for PWS pipeline. 2. FT-Transformer for model architecture."
            },
            "Implementation": "Inference model--FT-Transformer; PWS pipeline--Snorkel; Real-time feedback--JavaScript & Scala with QGIS"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Crowd feedback & HAI design guidelines",
            "Function": "Provide just-in-time feedback to improve labeling accuracy and user learning",
            "Embedded knowledge": {
                "Input or control techniques": "1. Real-time pop-up prompts when a mistake is inferred. 2. Options to view common mistakes and correct examples.",
                "Output or feedback methods": "1. Displaying rotating labeling tips. 2. Providing contextual help through example screens."
            },
            "Implementation": "Real-time feedback--JavaScript & Scala with QGIS"
        }
    ],
    "Results": {
        "Performance": "The intervention group demonstrated higher labeling precision overall and across all label types compared to the control group, with statistically significant differences for Curb Ramp and Missing Curb Ramp label types. No significant difference in labeling speed was observed.",
        "User feedback": "Participants generally found the pop-up prompts helpful and liked them. The intervention group reported higher self-confidence in identifying sidewalk features or problems. Some participants felt observed by the AI, while others felt assisted."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Traditional ML models requiring large volumes of annotated data",
                "This study": "LabelAId uses PWS to train on unannotated data, reducing the need for extensive manual labeling."
            },
            {
                "Previous studies": "Manual feedback to crowdworkers",
                "This study": "LabelAId provides AI-generated real-time feedback, improving labeling performance and user learning."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "LabelAId uses PWS to train on unannotated data, reducing the need for extensive manual labeling.",
                "Result": "The intervention group demonstrated higher labeling precision overall and across all label types compared to the control group."
            },
            {
                "Innovation": "LabelAId provides AI-generated real-time feedback, improving labeling performance and user learning.",
                "Result": "Participants generally found the pop-up prompts helpful and liked them. The intervention group reported higher self-confidence in identifying sidewalk features or problems."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Users with limited movement or physical disabilities",
        "Tasks": "Performing isometric muscle contractions in response to visual and tactile cues",
        "Application scenarios": "Interaction in virtual reality environments, assistive systems for users with physical disabilities, and rehabilitation"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Biofeedback mechanisms, muscle priming phenomenon",
            "Function": "Improve EMG-based interaction by reducing muscle response times",
            "Embedded knowledge": {
                "Architecture or framework": [
                    "1. Vienna Test System approach for EMG-based input in VR",
                    "2. Integration of visual, vibrotactile, and electrotactile cues for muscle stimulation"
                ],
                "Tool or tool kits": [
                    "1. Biosignalplux 4-Channel Hub for EMG signal acquisition",
                    "2. Sanitas SEM 47 EMS/TENS devices for electrotactile stimulation",
                    "3. Arduino Uno R3 microcontroller for controlling stimulation modalities"
                ]
            },
            "Implementation": "EMG signal acquisition--Biosignalplux 4-Channel Hub; Electrotactile stimulation--Sanitas SEM 47 EMS/TENS devices; Control system--Arduino Uno R3"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Muscle priming, biofeedback mechanisms",
            "Function": "Enhance muscle localization and activation speed through prior stimulation",
            "Embedded knowledge": {
                "Input or control techniques": [
                    "1. Visual cues using schematic anatomical drawings",
                    "2. Vibrotactile stimulation using vibration motors",
                    "3. Electrotactile stimulation using TENS impulses"
                ],
                "Output or feedback methods": [
                    "1. Real-time EMG signal monitoring and biofeedback",
                    "2. Visual feedback using an orange circle for muscle strength"
                ]
            },
            "Implementation": "Visual feedback--Unity Engine; Vibrotactile stimulation--Iduino TC-9520268 vibration motors; Electrotactile stimulation--Sanitas SEM 47 EMS/TENS devices"
        }
    ],
    "Results": {
        "Performance": "The study found that prior stimulation using visual, vibrotactile, and electrotactile cues significantly reduced EMG reaction times across all tested muscles. The calf muscle showed the fastest response times, and all prior stimulation modalities improved muscle response compared to no stimulation.",
        "User feedback": "Participants found tactile prior stimulation, particularly electrotactile, useful for muscle localization and favored it over visual cues. They noted that tactile modalities helped in quicker reaction times and better muscle localization. However, electrotactile stimulation was sometimes perceived as uncomfortable."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Previous studies focused on synchronous biofeedback during muscle activation.",
                "This study": "This study investigated the effect of prior stimulation on muscle response times, demonstrating significant improvements with visual, vibrotactile, and electrotactile cues."
            },
            {
                "Previous studies": "Previous research did not explore the specific impact of prior stimulation on different muscle locations.",
                "This study": "This study provided insights into the differential effects of prior stimulation on various muscles, with the calf muscle showing the fastest response times."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Investigated the effect of prior stimulation on muscle response times, demonstrating significant improvements with visual, vibrotactile, and electrotactile cues.",
                "Result": "The study found that prior stimulation using visual, vibrotactile, and electrotactile cues significantly reduced EMG reaction times across all tested muscles."
            },
            {
                "Innovation": "Provided insights into the differential effects of prior stimulation on various muscles, with the calf muscle showing the fastest response times.",
                "Result": "The calf muscle showed the fastest response times, and all prior stimulation modalities improved muscle response compared to no stimulation."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Users of smart devices such as smartwatches, VR/AR glasses, and IoT devices",
        "Tasks": "Silent speech recognition through depth sensing",
        "Application scenarios": "Smartwatches, VR/AR glasses, and environmentally deployed IoT devices for speech-based interactions"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Deep learning techniques, depth sensing, point cloud processing",
            "Function": "Enable accurate silent speech recognition using depth sensing",
            "Embedded knowledge": {
                "Architecture or framework": "1. Deep-learning model for lip localization using depth data. 2. Deep learning pipeline for point clouds to translate lip movements into commands and sentences.",
                "Tool or tool kits": "None"
            },
            "Implementation": "Depth data acquisition--TrueDepth camera; Lip segmentation--YOLOv7; Sequence-to-sequence speech recognition--PointVSR model"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Deep learning techniques, point cloud processing",
            "Function": "Provide new ways of inputting information through silent speech recognition",
            "Embedded knowledge": {
                "Input or control techniques": "1. Lip segmentation using depth data. 2. Point cloud standardization and alignment using TNet.",
                "Output or feedback methods": "None"
            },
            "Implementation": "Depth data acquisition--TrueDepth camera; Lip segmentation--YOLOv7; Sequence-to-sequence speech recognition--PointVSR model"
        }
    ],
    "Results": {
        "Performance": "PointVSR achieved a within-user Character Error Rate (CER) of 4.13% and a Word Error Rate (WER) of 8.06%, outperforming the RGB-based method with CER of 7.95% and WER of 13.02%. In cross-user validation, PointVSR achieved CER of 18.28% and WER of 29.14%, compared to the RGB-based method with CER of 23.28% and WER of 33.71%.",
        "User feedback": "Participants found the system effective and reliable across different sensor locations, with an average command recognition accuracy of 91.33% (within-user) and 74.88% (cross-user). The system demonstrated robustness against environmental variances and user postures."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Conventional RGB-based silent speech recognition methods",
                "This study": "Introduced depth sensing as a new information source for silent speech recognition, providing resilience against environmental factors and privacy concerns."
            },
            {
                "Previous studies": "RGB-based methods for lip segmentation",
                "This study": "Developed a lip segmentation model using depth data and YOLOv7, achieving high accuracy in lip detection."
            },
            {
                "Previous studies": "Traditional point cloud processing techniques",
                "This study": "Proposed a novel deep learning pipeline (PointVSR) for point cloud videos, including TNet for alignment and 4D point cloud convolution for feature extraction."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Introduced depth sensing as a new information source for silent speech recognition, providing resilience against environmental factors and privacy concerns.",
                "Result": "PointVSR achieved a within-user Character Error Rate (CER) of 4.13% and a Word Error Rate (WER) of 8.06%, outperforming the RGB-based method with CER of 7.95% and WER of 13.02%."
            },
            {
                "Innovation": "Developed a lip segmentation model using depth data and YOLOv7, achieving high accuracy in lip detection.",
                "Result": "Participants found the system effective and reliable across different sensor locations, with an average command recognition accuracy of 91.33% (within-user) and 74.88% (cross-user)."
            },
            {
                "Innovation": "Proposed a novel deep learning pipeline (PointVSR) for point cloud videos, including TNet for alignment and 4D point cloud convolution for feature extraction.",
                "Result": "In cross-user validation, PointVSR achieved CER of 18.28% and WER of 29.14%, compared to the RGB-based method with CER of 23.28% and WER of 33.71%."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Deaf users",
        "Tasks": "Evaluate and compare the usability of American Sign Language (ASL), Tap to Alexa, and smart home apps",
        "Application Scenarios": "Interacting with intelligent personal assistants in a limited-domain smart home environment"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Wizard-of-Oz methodology",
            "Function": "Evaluate and compare the usability of different input methods for deaf users",
            "Embedded knowledge": {
                "Architecture or framework": "1. Wizard-of-Oz setup for simulating ASL recognition 2. Use of Echo Show, Philips Hue lights, and Fire TV for smart home environment",
                "Tool or tool kits": "1. FaceTime for video link 2. Photo Booth for local recording 3. VNC Viewer for remote control"
            },
            "Implementation": "Video capture--HD webcam; Audio output--EarFun UBOOM 28W speaker; Audio input--Blue Yeti microphone"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Empirical analysis of user preferences and interactions",
            "Function": "Provide new ways for deaf users to interact with IPAs using ASL, touch, and apps",
            "Embedded knowledge": {
                "Input or control techniques": "1. ASL input via Wizard-of-Oz 2. Tap to Alexa for touch-based commands 3. Smart home apps for control via iPad",
                "Output or feedback methods": "1. Captions on Echo Show 2. Visual feedback from Philips Hue lights"
            },
            "Implementation": "ASL input--Wizard-of-Oz; Touch input--Tap to Alexa; App input--Smart home apps on iPad"
        }
    ],
    "Results": {
        "Performance": "ASL input showed a mean SUS of 71.6, indicating slightly above average usability. Tap to Alexa had a mean SUS of 61.4, and Apps with Alexa had a mean SUS of 56.3. The one-way repeated-measures ANOVA showed statistical significance with p = 0.015.",
        "User feedback": "Participants preferred ASL input over touch-based methods. They found fngerspelling more favorable than typing or tapping icons. The majority preferred eye gaze combined with signing or waving as wake methods. Captions were rated as the most important feature for ideal smart home systems."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Limited research on ASL-based interaction with IPAs",
                "This study": "Implemented a Wizard-of-Oz setup to simulate ASL recognition and evaluated its usability compared to touch-based methods"
            },
            {
                "Previous studies": "Traditional IPAs rely heavily on voice input",
                "This study": "Explored alternative input methods for deaf users, including ASL, Tap to Alexa, and smart home apps"
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Implemented a Wizard-of-Oz setup to simulate ASL recognition and evaluated its usability compared to touch-based methods",
                "Result": "ASL input showed a mean SUS of 71.6, indicating slightly above average usability. Tap to Alexa had a mean SUS of 61.4, and Apps with Alexa had a mean SUS of 56.3. The one-way repeated-measures ANOVA showed statistical significance with p = 0.015."
            },
            {
                "Innovation": "Explored alternative input methods for deaf users, including ASL, Tap to Alexa, and smart home apps",
                "Result": "Participants preferred ASL input over touch-based methods. They found fngerspelling more favorable than typing or tapping icons. The majority preferred eye gaze combined with signing or waving as wake methods. Captions were rated as the most important feature for ideal smart home systems."
            }
        ]
    }
}

{
    "Target Definition": {
        "Target User Group": "General data visualization users",
        "Tasks": "Comparing and estimating differences and relative growth between bars in bar charts",
        "Application scenarios": "Data visualization and presentation in various fields such as journalism, business reporting, and scientific research"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Algebraic Visualization Design, Graphical Perception Theory",
            "Function": "Systematically analyze the effects of y-axis truncation on user performance in grouped bar charts",
            "Embedded knowledge": {
                "Architecture or framework": "1. Defined y-axis truncations that preserve underlying data relations as monotonic. 2. Categorized data relations into concordant and discordant types to analyze truncation effects.",
                "Tool or tool kits": "1. Online survey platform for testing user performance. 2. Vega-Altair for generating visual stimuli."
            },
            "Implementation": "Stimuli Generation--Vega-Altair; Survey Platform--Qualtrics"
        }
    ],
    "Results": {
        "Performance": "For tasks comparing or estimating differences between bars, y-axis truncation has minimal impact on user performance. For tasks comparing or estimating percentage changes, monotonic truncation performs similarly to no truncation, while non-monotonic truncation significantly worsens performance.",
        "User feedback": "Participants found the tasks involving percentage changes more challenging, with lower accuracy rates. The study suggests that non-monotonic truncation biases estimates upwards, while monotonic truncation maintains accuracy similar to no truncation."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Did not systematically categorize truncation types based on data relations.",
                "This study": "Defined and analyzed monotonic and non-monotonic truncations, providing empirical evidence on their effects on user performance."
            },
            {
                "Previous studies": "Focused on subjective perception of effect size without detailed task-based analysis.",
                "This study": "Provided a rigorous task-based analysis of y-axis truncation effects, differentiating between tasks unaffected and affected by truncation."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Defined and analyzed monotonic and non-monotonic truncations, providing empirical evidence on their effects on user performance.",
                "Result": "For tasks comparing or estimating differences between bars, y-axis truncation has minimal impact on user performance. For tasks comparing or estimating percentage changes, monotonic truncation performs similarly to no truncation, while non-monotonic truncation significantly worsens performance."
            },
            {
                "Innovation": "Provided a rigorous task-based analysis of y-axis truncation effects, differentiating between tasks unaffected and affected by truncation.",
                "Result": "Participants found the tasks involving percentage changes more challenging, with lower accuracy rates. The study suggests that non-monotonic truncation biases estimates upwards, while monotonic truncation maintains accuracy similar to no truncation."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "ML developers and practitioners",
        "Tasks": "Identify and debug biases in pre-trained text representations",
        "Application Scenarios": "Exploring biases in word embeddings and language models"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Relative Norm Difference algorithm",
            "Function": "Explore, debug, and understand biases in pre-trained text representations",
            "Embedded knowledge": {
                "Architecture or framework": "1. Chord diagram visualization for bias overview. 2. Instance view for tracing biases back to training data. 3. Domain Lens for topic-based data exploration. 4. Bias Editor for defining and customizing bias types.",
                "Tool or tool kits": "1. Interactive system for bias detection and debugging. 2. Visualization tools for bias exploration."
            },
            "Implementation": "Bias detection--Relative Norm Difference; Visualization--Chord Diagram; Data exploration--Domain Lens; Bias customization--Bias Editor"
        }
    ],
    "Results": {
        "Performance": "Participants using Stile detected more biases (4.73 biases on average) compared to WordBias (3.40 biases on average). All biases detected using Stile were correct, while only 2.87 out of 3.40 biases detected using WordBias were correct.",
        "User feedback": "Participants appreciated the interactivity and responsiveness of Stile, the ability to trace biases back to the training data, and the visualization. However, some found the chord diagram overwhelming initially."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Limited to pre-defined biases and lack effective interaction support.",
                "This study": "Provides interactive support for mixed-initiative bias discovery and debugging, allowing users to define and customize biases, and trace biases back to training data."
            },
            {
                "Previous studies": "WordBias visualizes biases using parallel coordinates, limited to two subgroups.",
                "This study": "Uses a chord diagram to visualize biases involving multiple subgroups, addressing the scalability issue."
            },
            {
                "Previous studies": "No mechanism to trace biases back to training data.",
                "This study": "Instance view allows users to trace biases back to specific sentences in the training data, providing context for how biases are developed."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Provides interactive support for mixed-initiative bias discovery and debugging, allowing users to define and customize biases, and trace biases back to training data.",
                "Result": "Participants detected more biases and developed deeper insights using Stile compared to WordBias."
            },
            {
                "Innovation": "Uses a chord diagram to visualize biases involving multiple subgroups, addressing the scalability issue.",
                "Result": "Participants found the chord diagram helpful for quickly exploring biases, though some found it initially overwhelming."
            },
            {
                "Innovation": "Instance view allows users to trace biases back to specific sentences in the training data, providing context for how biases are developed.",
                "Result": "Participants appreciated the ability to trace biases back to training data, which helped them understand the source of biases."
            }
        ]
    }
}

{
    "Target Definition": {
        "Target User Group": "Pedestrians",
        "Tasks": "Crossing streets safely in the presence of autonomous vehicles",
        "Application scenarios": "Urban environments with mixed traffic of autonomous and manually driven vehicles"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "V2X communication technologies",
            "Function": "Provide pedestrians with clear and unified information from multiple AVs",
            "Embedded knowledge": {
                "Architecture or framework": "1. Interconnected eHMIs where multiple AV interfaces are networked to provide coherent cues. 2. Centralized communication approach where one AV projects the zebra crossing.",
                "Tool or tool kits": "1. Custom 3D model of the light band. 2. Emissive material for zebra crossing projection."
            },
            "Implementation": "VR simulation--Unity 3D; Hardware--Oculus Quest 2; Light band--Custom 3D model; Zebra crossing projection--Emissive material"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Human-machine interaction principles",
            "Function": "Enhance pedestrian safety and crossing experience",
            "Embedded knowledge": {
                "Input or control techniques": "1. Light band on AV bumper to indicate vehicle state. 2. Zebra crossing projection to signal safe crossing opportunities.",
                "Output or feedback methods": "1. Red/green crosswalk projection to indicate safety status. 2. Wi-Fi symbol to indicate vehicle connectivity."
            },
            "Implementation": "Crossing signals--Light band and zebra crossing projection; Connectivity indication--Wi-Fi symbol"
        }
    ],
    "Results": {
        "Performance": "Interconnected eHMIs enhanced safety feelings and encouraged cautious crossings. Collisions were highest in the Interconnected condition, but none were due to misinterpretation of signals.",
        "User feedback": "Participants felt safer with eHMIs compared to no eHMIs. The red crosswalk induced caution, while the green crosswalk was perceived as clear and easy to understand. The Wi-Fi symbol caused confusion."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Traditional eHMIs primarily convey the intentions of individual vehicles.",
                "This study": "Interconnected eHMIs provide insights into multiple vehicles, reducing signal misinterpretations."
            },
            {
                "Previous studies": "eHMIs often evaluated in isolation, focusing on single vehicle-pedestrian interactions.",
                "This study": "Interconnected eHMIs are tested in mixed traffic environments, considering multiple AVs and manually driven vehicles."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Interconnected eHMIs provide insights into multiple vehicles, reducing signal misinterpretations.",
                "Result": "Enhanced safety feelings and cautious crossings, though highest collisions in Interconnected condition."
            },
            {
                "Innovation": "Interconnected eHMIs are tested in mixed traffic environments, considering multiple AVs and manually driven vehicles.",
                "Result": "Participants felt safer with eHMIs compared to no eHMIs. The red crosswalk induced caution, while the green crosswalk was perceived as clear and easy to understand."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Anime directors and storyboard artists",
        "Tasks": "Creating digital storyboards for anime production",
        "Application Scenarios": "Anime production, including pre-production and production phases"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "User-centered design approach, Instrumental interaction theory",
            "Function": "Enhance the entire storyboarding experience for anime production",
            "Embedded knowledge": {
                "Architecture or framework": "1. Web-based system for casual use on tablets, PCs, and smartphones. 2. Vertical timeline interface to avoid hand occlusion and ensure continuity.",
                "Tool or tool kits": "1. Griffith: A digital system for creating storyboards. 2. Discrete instruments like a pressure-sensitive brush, eraser, undo/redo tools, stopwatch, and previsualization tool."
            },
            "Implementation": "Web-based application--JavaScript, HTML, CSS; Pressure-sensitive brush--Canvas API; Previsualization--Custom JavaScript player"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Instrumental interaction theory",
            "Function": "Provide new ways of inputting and controlling storyboard creation",
            "Embedded knowledge": {
                "Input or control techniques": "1. Pressure-sensitive brush for varied stroke widths. 2. Reframing tool for adjusting scene illustrations. 3. Local undo and redo actions tied to the currently visible frame.",
                "Output or feedback methods": "1. Vertical timeline to avoid hand occlusion. 2. Previsualization player for checking sequences of frames."
            },
            "Implementation": "Pressure-sensitive brush--Canvas API; Reframing tool--Custom JavaScript functions; Previsualization player--Custom JavaScript player"
        },
        {
            "Innovation type": "Design",
            "Supporting knowledge": "User-centered design approach",
            "Function": "Improve the storyboarding process for anime production",
            "Embedded knowledge": {
                "Prototype, script or models": "1. Vertical timeline interface. 2. Overview interface for grasping the holistic view. 3. Infinite canvas with vector-based sketching.",
                "Material or crafts": "1. Digital E-conte export with QR codes for linking to digital versions."
            },
            "Implementation": "Vertical timeline--JavaScript and CSS; Overview interface--JavaScript and CSS; Infinite canvas--Canvas API"
        }
    ],
    "Results": {
        "Performance": "Griffith was able to support the creation of over 700 frames and 148 cuts within a week by an experienced anime director. The system facilitated smooth navigation, sketching, and previsualization, significantly improving the storyboarding process.",
        "User feedback": "Professionals appreciated the casual use, previsualization feature, overview interface, and local undo/redo actions. They also valued the ability to share the latest E-conte with others. Suggestions for improvement included adding layers, importing reference materials, and specifying camera work."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Conventional storyboarding tools like Storyboard Pro and TVPaint Animation with horizontal timelines and limited integration of auxiliary tools.",
                "This study": "Introduced a web-based system with a vertical timeline, infinite canvas, and discrete instruments like a stopwatch and previsualization tool for enhanced storyboarding."
            },
            {
                "Previous studies": "Traditional E-conte authoring with paper and pen, requiring manual timing and previsualization.",
                "This study": "Implemented digital tools for timing (stopwatch) and previsualization, reducing cognitive workload and improving efficiency."
            },
            {
                "Previous studies": "Limited support for casual and private use in existing storyboarding tools.",
                "This study": "Designed Griffith for casual use on various devices, allowing instant access and sharing of the latest E-conte information."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Web-based system with vertical timeline, infinite canvas, and discrete instruments.",
                "Result": "Supported the creation of over 700 frames and 148 cuts within a week, improving the storyboarding process."
            },
            {
                "Innovation": "Digital tools for timing and previsualization.",
                "Result": "Reduced cognitive workload and improved efficiency in the storyboarding process."
            },
            {
                "Innovation": "Designed for casual use on various devices.",
                "Result": "Allowed instant access and sharing of the latest E-conte information, enhancing collaboration and efficiency."
            }
        ]
    }
}

{
    "Target Definition": {
        "Target User Group": "None",
        "Tasks": "None",
        "Application scenarios": "None"
    },
    "Contributions": [],
    "Results": {
        "Performance": "None",
        "User feedback": "None"
    },
    "Second Extraction": {
        "Innovations": [],
        "Quadruple": []
    }
}
{
    "Target Definition": {
        "Target User Group": "Artists and designers",
        "Tasks": "Creating 3D ink paintings using free-form 3D ink strokes",
        "Application scenarios": "Gaming, animation, and virtual reality (VR) industry"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Design study involving artists and designers",
            "Function": "Create 3D ink paintings using free-form 3D ink strokes",
            "Embedded knowledge": {
                "Architecture or framework": [
                    "InkBrush as a plugin for Blender, a popular 3D modeling tool",
                    "Dynamic generation of ink textures to replicate the distinct characteristics of ink strokes"
                ],
                "Tool or tool kits": [
                    "InkBrush provides a digital calligraphy brush and various editing tools",
                    "Tools for adjusting parameters such as moisture, color, darkness, dryness, and stroke style"
                ]
            },
            "Implementation": "3D modeling--Blender; Ink texture generation--Static textures; Stroke mesh generation--Bezier curve fitting"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "User study involving 75 participants and expert feedback",
            "Function": "Allow artists to sketch ink strokes freely on a 3D canvas using a mouse",
            "Embedded knowledge": {
                "Input or control techniques": [
                    "2D panel mode for drawing on a 2D panel parallel to the screen",
                    "Surface mode for drawing ink strokes directly onto the surface of a 3D object"
                ],
                "Output or feedback methods": [
                    "Real-time rendering of 3D ink strokes with attributes like hairy edges, ink drips, and scattered dots",
                    "Adjustable parameters for ink texture attributes such as moisture, darkness, and trailing"
                ]
            },
            "Implementation": "3D canvas--Blender; Real-time rendering--Blender plugin"
        }
    ],
    "Results": {
        "Performance": "InkBrush was found to be effective and easy to use, with an average SUS score of 79.3. Participants were able to create compelling 3D ink paintings, and expert evaluations further demonstrated its effectiveness.",
        "User feedback": "Participants expressed satisfaction with InkBrush, highlighting its ability to achieve realistic 3D ink effects and its intuitive interface. The tool was praised for its versatility and efficiency in creating 3D ink paintings."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Existing 3D modeling tools require manual modeling and texturing, or converting 2D ink paintings into 3D format.",
                "This study": "InkBrush allows freehand drawing of 3D ink paintings using a digital calligraphy brush and various editing tools, integrated as a plugin for Blender."
            },
            {
                "Previous studies": "Current methods lack tools for freehand drawing of realistic 3D ink strokes.",
                "This study": "InkBrush offers 2D panel mode and surface mode for drawing ink strokes, with real-time rendering and adjustable parameters for ink texture attributes."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "InkBrush as a plugin for Blender, a popular 3D modeling tool",
                "Result": "InkBrush was found to be effective and easy to use, with an average SUS score of 79.3. Participants were able to create compelling 3D ink paintings, and expert evaluations further demonstrated its effectiveness."
            },
            {
                "Innovation": "InkBrush allows freehand drawing of 3D ink paintings using a digital calligraphy brush and various editing tools",
                "Result": "Participants expressed satisfaction with InkBrush, highlighting its ability to achieve realistic 3D ink effects and its intuitive interface. The tool was praised for its versatility and efficiency in creating 3D ink paintings."
            }
        ]
    }
}

{
    "Target Definition": {
        "Target User Group": "Users interacting with 3D environments, especially in VR/AR settings",
        "Tasks": "Selecting targets in 3D environments",
        "Application scenarios": "Virtual and augmented reality environments where precise target selection is required"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Biomechanical simulation, RL-based policy training",
            "Function": "Infer intended targets in 3D environments with high accuracy and low latency",
            "Embedded knowledge": {
                "Architecture or framework": "1. Biomechanical simulation framework for generating realistic human motion data. 2. RL-based action policy for simulating user behavior in target selection tasks.",
                "Tool or tool kits": "1. Inference network trained on simulated data for real-time target prediction. 2. Visual-suggestion-based assistance system for VR target selection."
            },
            "Implementation": "VR environment setup--Meta Quest 2; Biomechanical simulation--MuJoCo; Inference network--PyTorch, ONNX, Unity Barracuda engine"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Probabilistic inference, Neural density estimation",
            "Function": "Assist users in selecting targets more efficiently by providing visual suggestions based on inferred targets",
            "Embedded knowledge": {
                "Input or control techniques": "1. Raycasting for target selection in VR. 2. Visual-suggestion-based assistance with sticky ray and target highlighting.",
                "Output or feedback methods": "1. Visual suggestions based on inferred targets. 2. Confidence-based selective activation of visual suggestions."
            },
            "Implementation": "VR environment setup--Meta Quest 2; Visual-suggestion assistance--Unity"
        }
    ],
    "Results": {
        "Performance": "The simulation-based inference method significantly improved target selection accuracy by 71% and reduced completion time by 35% compared to naive selection. The inference model achieved an accuracy of 88% when observing the first 80% of each trial.",
        "User feedback": "Participants reported improved efficiency and accuracy in target selection tasks. The selective visual suggestions based on inference confidence were particularly appreciated for reducing distractions in dense target configurations."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Traditional data-driven methods rely on extensive human datasets, which are costly and time-consuming to collect.",
                "This study": "Introduced a biomechanical simulation-based approach to generate realistic motion data, reducing the need for extensive human data collection."
            },
            {
                "Previous studies": "Heuristic methods like nearest neighbor often fail in dense target configurations due to high error rates.",
                "This study": "Implemented a neural inference method that provides confidence-based selective visual suggestions, improving accuracy in dense target configurations."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Biomechanical simulation-based approach to generate realistic motion data",
                "Result": "Reduced the need for extensive human data collection while achieving high inference accuracy."
            },
            {
                "Innovation": "Neural inference method with confidence-based selective visual suggestions",
                "Result": "Improved accuracy in dense target configurations, reducing distractions and enhancing user performance."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Users interacting with large language models (LLMs)",
        "Tasks": "Evaluating different denial styles of LLMs when they cannot fulfill user requests",
        "Application Scenarios": "Interactions where LLMs are unable to fulfill user requests due to technical limitations or social policy restrictions"
    },
    "Contributions": [
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Politeness theory, Repair strategies",
            "Function": "Reduce user frustration and improve satisfaction when LLMs deny requests",
            "Embedded knowledge": {
                "Input or control techniques": "1. Baseline denials: Simple refusal without explanation. 2. Factual denials: Providing a reason for the denial. 3. Diverting denials: Steering away from the request and providing related information. 4. Opinionated denials: Emphasizing the inappropriateness of the request.",
                "Output or feedback methods": "1. Providing alternative information or suggestions. 2. Offering explanations for denials."
            },
            "Implementation": "LLM interaction--Gradio & GPT-4"
        }
    ],
    "Results": {
        "Performance": "Diverting denials resulted in lower frustration and higher satisfaction compared to baseline denials. Factual denials were rated lower than diverting denials on all measures but frustration.",
        "User feedback": "Participants appreciated diverting denials for providing valuable information even when the original request could not be fulfilled. Baseline denials were perceived as frustrating and unhelpful."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Baseline denials without explanations",
                "This study": "Introduced diverting denials that provide alternative information to reduce frustration and improve satisfaction"
            },
            {
                "Previous studies": "Factual denials providing reasons for denials",
                "This study": "Showed that diverting denials are more effective than factual denials in reducing frustration and improving satisfaction"
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Introduced diverting denials that provide alternative information to reduce frustration and improve satisfaction",
                "Result": "Diverting denials resulted in lower frustration and higher satisfaction compared to baseline denials"
            },
            {
                "Innovation": "Showed that diverting denials are more effective than factual denials in reducing frustration and improving satisfaction",
                "Result": "Factual denials were rated lower than diverting denials on all measures but frustration"
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Wheelchair users, blind and low-vision participants, families with young children, caregivers, and occupational therapists",
        "Tasks": "Scan home spaces and detect potential accessibility and safety issues in real time",
        "Application scenarios": "Home safety and accessibility auditing, remote assessment by occupational therapists, planning renovations, and verifying rental spaces for accessibility"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "ADA Design Guidelines, Home Safety Self Assessment Tool (HSSAT), US Fair Housing Act Design Manual",
            "Function": "Identify, localize, and visualize indoor accessibility and safety issues",
            "Embedded knowledge": {
                "Architecture or framework": [
                    "Combines Apple’s RoomPlan API and a customized YOLOV5 model for real-time indoor reconstruction",
                    "Custom JSON-based rubric for encoding accessibility and safety issues"
                ],
                "Tool or tool kits": [
                    "Custom YOLOV5 model trained to detect nine categories of smaller indoor items relevant to accessibility",
                    "Interactive 3D room reconstruction with a summary of findings"
                ]
            },
            "Implementation": "LiDAR and RGB camera--Apple’s RoomPlan API; Object detection--YOLOV5 model; Real-time parametric model--3D scene reconstruction"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "User feedback from formative study, ADA compliance guidelines",
            "Function": "Help users identify and verify accessibility and safety issues in their homes",
            "Embedded knowledge": {
                "Input or control techniques": [
                    "Real-time scanning with LiDAR and computer vision",
                    "Raycasting to convert 2D bounding box detections into 3D coordinates"
                ],
                "Output or feedback methods": [
                    "AR overlays for detected issues",
                    "Interactive 3D model for post-scan summary",
                    "Audio feedback for blind or low-vision users"
                ]
            },
            "Implementation": "AR visualization--Apple’s ARKit; Audio feedback--VoiceOver compatibility"
        }
    ],
    "Results": {
        "Performance": "RASSAR achieved an average precision of 0.86 and recall of 0.83 in technical evaluation, and 0.79 precision and 0.73 recall in user study. Scans were 3.5x faster than manual auditing.",
        "User feedback": "Participants rated the app highly usable (avg=5.6/7) and accurate (avg=5.8/7). They found it useful for identifying potential issues and appreciated the audio feedback feature."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Manual home safety checklists and professional OT assessments",
                "This study": "Semi-automatic, real-time detection and visualization of accessibility and safety issues using mobile AR and LiDAR"
            },
            {
                "Previous studies": "Traditional methods relying on physical measurements and professional expertise",
                "This study": "Customizable JSON-based rubric for encoding and detecting accessibility issues tailored to individual needs"
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Semi-automatic, real-time detection and visualization of accessibility and safety issues using mobile AR and LiDAR",
                "Result": "RASSAR achieved an average precision of 0.86 and recall of 0.83 in technical evaluation, and 0.79 precision and 0.73 recall in user study. Scans were 3.5x faster than manual auditing."
            },
            {
                "Innovation": "Customizable JSON-based rubric for encoding and detecting accessibility issues tailored to individual needs",
                "Result": "Participants rated the app highly usable (avg=5.6/7) and accurate (avg=5.8/7). They found it useful for identifying potential issues and appreciated the audio feedback feature."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Individuals learning motor skills and movements",
        "Tasks": "Learning and performing specific motor skills, postures, or movements",
        "Application scenarios": "Training in sports, healthcare, and industrial applications"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Literature survey and citation trails",
            "Function": "Assist individuals in learning and achieving specific motor skills, postures, or movements",
            "Embedded knowledge": {
                "Architecture or framework": "1. Design space for motion feedforward and corrective feedback. 2. Interaction effects between feedforward and feedback. 3. Common design approaches in XR-based motion guidance.",
                "Tool or tool kits": "1. Basic prototypes of each of the 9 configurations to demonstrate their functionality."
            },
            "Implementation": "Motion guidance system--XR technologies; Feedforward and feedback visualization--Various perspectives and contextual cues"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Design dimensions for feedforward and feedback",
            "Function": "Provide instructional cues and corrective feedback for motor skill training",
            "Embedded knowledge": {
                "Input or control techniques": "1. Discrete guidance: cues for next critical posture. 2. Continuous guidance: cues for next frame in motion sequence. 3. Autonomous guidance: operates independently of trainee’s actions.",
                "Output or feedback methods": "1. Color changes to indicate alignment status. 2. Directional arrows to guide corrections. 3. Graphs for post-hoc analysis of errors."
            },
            "Implementation": "Feedforward and feedback visualization--XR platforms; Real-time and post-hoc feedback--Various visual cues"
        }
    ],
    "Results": {
        "Performance": "The study identifies common design approaches and potential research opportunities in XR-based motion guidance systems, providing a comprehensive design space for motion feedforward and corrective feedback.",
        "User feedback": "The study highlights the importance of perspective, level of indirection, and interactive update strategies in designing effective motion guidance systems. Users benefit from clear and intuitive visual cues for learning and correcting motor skills."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Focused on either feedforward or feedback, not both.",
                "This study": "Considers both feedforward and corrective feedback, exploring their interaction effects and providing a comprehensive design space."
            },
            {
                "Previous studies": "Limited to traditional 2D displays and pointing devices.",
                "This study": "Utilizes XR technologies to create novel and effective guidance systems with immersive and interactive visualizations."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Considers both feedforward and corrective feedback, exploring their interaction effects and providing a comprehensive design space.",
                "Result": "The study identifies common design approaches and potential research opportunities in XR-based motion guidance systems, providing a comprehensive design space for motion feedforward and corrective feedback."
            },
            {
                "Innovation": "Utilizes XR technologies to create novel and effective guidance systems with immersive and interactive visualizations.",
                "Result": "The study highlights the importance of perspective, level of indirection, and interactive update strategies in designing effective motion guidance systems. Users benefit from clear and intuitive visual cues for learning and correcting motor skills."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Children under 16",
        "Tasks": "Safeguarding children from harassment in social VR",
        "Application scenarios": "Social Virtual Reality environments where children interact with other users"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Child online safety and psychology",
            "Function": "Create safer spaces for children in social VR by mitigating harmful interactions",
            "Embedded knowledge": {
                "Architecture or framework": "1. Automated Embodied Moderators (AEMs) that provide immediate action and support. 2. Positive reinforcement and restorative justice approaches.",
                "Tool or tool kits": "1. Big Buddy: A Wizard-of-Oz AEM prototype that intervenes in child harassment situations."
            },
            "Implementation": "Simulated social VR game--Big Buddy; Moderation actions--Immediate intervention, reflection space, educational breaks"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Child development and educational psychology",
            "Function": "Help children feel safe and supported in social VR",
            "Embedded knowledge": {
                "Input or control techniques": "1. Customizable AEM appearance and communication features. 2. User-initiated AEM interventions.",
                "Output or feedback methods": "1. Visual and verbal reminders of rules. 2. Positive reinforcement messages."
            },
            "Implementation": "Social VR platforms--Customizable AEM; Interaction techniques--User-initiated interventions, visual and verbal feedback"
        },
        {
            "Innovation type": "Design",
            "Supporting knowledge": "Participatory design with children, guardians, and experts",
            "Function": "Enhance child engagement and credibility of AEMs",
            "Embedded knowledge": {
                "Prototype, script or models": "1. Child-designed AEMs with various appearances (e.g., Pikachu, superheroes). 2. Storyboarding harassment scenarios with AEM interventions.",
                "Material or crafts": "1. Drawing and storyboarding tools for children to design their AEMs."
            },
            "Implementation": "Design activity--Drawing and storyboarding; Customization parameters--Appearance, communication features, intervention methods"
        }
    ],
    "Results": {
        "Performance": "The study found that AEMs can effectively enforce rules, provide immediate actions, and offer support to children in social VR. Positive reinforcement and tailored interventions were recommended for long-term behavioral change.",
        "User feedback": "Experts, guardians, and children found AEMs beneficial for creating safer spaces in social VR. Children preferred customizable AEMs that could intervene discreetly, while adults emphasized the importance of positive reinforcement and reflection."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Existing safety tools in social VR rely on user-initiated actions like blocking and reporting.",
                "This study": "Introduces Automated Embodied Moderators (AEMs) that provide immediate action and support, with positive reinforcement and restorative justice approaches."
            },
            {
                "Previous studies": "Human moderators in social VR are limited in availability and effectiveness.",
                "This study": "Proposes AEMs that can be present 24/7, offering immediate interventions and psychological support."
            },
            {
                "Previous studies": "Moderation in social VR often lacks child-centered design and customization.",
                "This study": "Involves children in the design process, allowing them to customize AEM appearance and communication features."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Introduces Automated Embodied Moderators (AEMs) that provide immediate action and support, with positive reinforcement and restorative justice approaches.",
                "Result": "AEMs can effectively enforce rules, provide immediate actions, and offer support to children in social VR."
            },
            {
                "Innovation": "Proposes AEMs that can be present 24/7, offering immediate interventions and psychological support.",
                "Result": "Experts, guardians, and children found AEMs beneficial for creating safer spaces in social VR."
            },
            {
                "Innovation": "Involves children in the design process, allowing them to customize AEM appearance and communication features.",
                "Result": "Children preferred customizable AEMs that could intervene discreetly, enhancing their engagement and trust."
            }
        ]
    }
}
{
  "Target Definition": {
    "Target User Group": "Users interested in learning dance through VR",
    "Tasks": "Follow a pre-defined choreography with pre-defined timing",
    "Application scenarios": "Dance games and dance classes organized in VR or in real-life"
  },
  "Contributions": [
    {
      "Innovation type": "Interaction techniques",
      "Supporting knowledge": "Mimetic method, kinesthetic lag, anticipatory timeline presentation",
      "Function": "Help users anticipate and follow dance movements accurately",
      "Embedded knowledge": {
        "Input or control techniques": [
          "1. Multiple model dancers performing the choreography with different time offsets to provide anticipatory visualization."
        ],
        "Output or feedback methods": [
          "1. Visualization of multiple lines of dancers at different locations to minimize visual occlusion and allow peripheral vision."
        ]
      },
      "Implementation": "Dance choreography instruction--Oculus Quest 2"
    }
  ],
  "Results": {
    "Performance": "WAVE resulted in statistically significantly lower position-based movement error (mean = 0.47, SD = 0.08) compared to the baseline (mean = 0.50, SD = 0.08), with a small effect size (Cohen’s d = 0.36). Direction-based movement error was also significantly lower with WAVE (mean = 0.40, SD = 0.04) compared to the baseline (mean = 0.43, SD = 0.04), with a large effect size (Cohen’s d = 0.81).",
    "User feedback": "20 out of 36 participants preferred WAVE over the baseline. However, subjective performance ratings showed no statistically significant differences between WAVE and the baseline in terms of perceived movement and timing accuracy."
  },
  "Second Extraction": {
    "Innovations": [
      {
        "Previous studies": "Dance games and VR dance instruction typically use symbolic abstraction of movements or require practice modes for learning choreography.",
        "This study": "Proposed WAVE, an anticipatory movement visualization technique using multiple model dancers with different time offsets to instruct full-body choreography in real-time without prior learning or memorization."
      }
    ],
    "Quadruple": [
      {
        "Innovation": "Proposed WAVE, an anticipatory movement visualization technique using multiple model dancers with different time offsets to instruct full-body choreography in real-time without prior learning or memorization.",
        "Result": "WAVE resulted in statistically significantly lower position-based and direction-based movement errors compared to the baseline, indicating improved accuracy in following the choreography."
      }
    ]
  }
}

{
    "Target Definition": {
        "Target User Group": "Ride-hailing drivers",
        "Tasks": "Interacting with facial verification technology (FVT) in the context of ride-hail work",
        "Application scenarios": "Gig work, specifically ride-hailing services"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "sociotechnical approach, human-centered design, facial recognition technology",
            "Function": "Provide a sociotechnical analysis of facial verification technology in gig work",
            "Embedded knowledge": {
                "Architecture or framework": "1. Analysis of drivers’real-time self-reported behaviors using online forums data 2. Development of a framework that integrates theories from HCI, CSCW, Science and Technology Studies (STS)"
            },
            "Implementation": "Python programming language--Scrapy web crawling tool; Python programming language--Regular expressions for post-processing data; etc."
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "articulation labor, sociotechnical approach, human-centered design",
            "Function": "Provide an analysis of how ride-hailing drivers articulate and repair facial verification technology in their work",
            "Embedded knowledge": {
                "Input or control techniques": "1. Development of an analysis framework for drivers’articulation and repair strategies using sociotechnical theory and CSCW 2. Application of human-centered design to examine how ride-hailing drivers articulate and repair facial verification technology",
                "Output or feedback methods": "None mentioned in the study"
            },
            "Implementation": "Qualitative analysis--Python programming language; NVivo coding tool; etc."
        },
        {
            "Innovation type": "Design",
            "Supporting knowledge": "human-centered design, sociotechnical approach, CSCW",
            "Function": "Design an approach to analyze ride-hailing drivers’real-time self-reported behaviors using online forums data",
            "Embedded knowledge": {
                "Prototype, script or models": "None mentioned in the study",
                "Material or crafts": "None mentioned in the study"
            },
            "Implementation": "Python programming language--Scrapy web crawling tool; Python programming language--Regular expressions for post-processing data; etc."
        }
    ],
    "Results": {
        "Performance": "The study reveals the complex articulation labor that ride-hailing drivers engage in to comply with facial verification technology. It also highlights the multiple and varied interpretations that drivers have of facial verification technology. ",
        "User feedback": "Drivers experience various forms of labor in their efforts to comply with facial verification technology. These efforts involve significant investments of money, time, and resourcefulness."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Focusing on how to make biometric technologies seamless",
                "This study": "Showing how such technologies require significant labor and can produce multiple and varied interpretations among drivers"
            },
            {
                "Previous studies": "Not providing enough analysis on articulation labor and its relation to biometric technologies",
                "This study": "Analyzing articulation labor in relation to facial verification technology in gig work"
            },
            {
                "Previous studies": "Limited attention to drivers’ experiences with facial verification technology",
                "This study": "Providing an in-depth analysis of drivers’real-time self-reported behaviors using online forums data and a sociotechnical approach"
            }
        ],
        "Quadruple": [
            {
                "Innovation": "facial verification technology",
                "Result": "drivers experience various forms of labor in their efforts to comply with facial verification technology"
            },
            {
                "Innovation": "analyzing articulation labor",
                "Result": "reveals the complex articulation labor that ride-hailing drivers engage in to comply with facial verification technology"
            },
            {
                "Innovation": "human-centered design approach",
                "Result": "Design an approach that provides a holistic understanding of drivers’real-time self-reported behaviors using online forums data"
            }
        ]
    }
}

{
    "Target Definition": {
        "Target User Group": "Essential workers in waste labor industries",
        "Tasks": "Managing the introduction of AI and automation technologies in their workplaces",
        "Application scenarios": "Waste labor industries, such as recycling facilities and airports, during the COVID-19 pandemic"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Ethnographic research, CSCW, and HCI",
            "Function": "Integrate AI and automation technologies in waste labor industries",
            "Embedded knowledge": {
                "Architecture or framework": "Patchwork, a concept that highlights the human labor necessary to integrate AI in the social and material environments it is intended to augment",
                "Tool or tool kits": "None"
            },
            "Implementation": "Ethnographic fieldnotes, interviews, and observations"
        }
    ],
    "Results": {
        "Performance": "The study found that the introduction of AI and automation technologies in waste labor industries led to new forms of labor for essential staff, requiring increased attention and responsibility",
        "User feedback": "The study highlights the importance of considering the often-undervalued frontline work that makes up for AI’s shortcomings during implementation"
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Previous research has focused on the benefits of AI and automation technologies in various industries",
                "This study": "This study highlights the importance of considering the human labor necessary to integrate AI in waste labor industries"
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Patchwork, a concept that highlights the human labor necessary to integrate AI in the social and material environments it is intended to augment",
                "Result": "The study found that the introduction of AI and automation technologies in waste labor industries led to new forms of labor for essential staff, requiring increased attention and responsibility"
            }
        ]
    }
}

{
    "Target Definition": {
        "Target User Group": "Creative professionals of color",
        "Tasks": "Navigating racial capitalism online, building communities, performing authenticity, and managing creative ownership",
        "Application scenarios": "Social media platforms, digital creative industries"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Racial capitalism, critical race theory",
            "Function": "Understand how racial capitalism influences the experiences and performance of race among creatives of color on digital platforms",
            "Embedded knowledge": {
                "Architecture or framework": "None",
                "Tool or tool kits": "None"
            },
            "Implementation": "None"
        }
    ],
    "Results": {
        "Performance": "The study found that creative professionals of color experience the effects of racial capitalism online, particularly with respect to topics of creative ownership and authenticity.",
        "User feedback": "Participants called for digital platforms to make changes that allow for safe authentic sharing of their work and identities as well as equitable recognition of their labor and value."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Prior research on racial capitalism and critical race theory",
                "This study": "Applies racial capitalism to understand the work of creative professionals of color on digital platforms"
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Applies racial capitalism to understand the work of creative professionals of color on digital platforms",
                "Result": "Found that creative professionals of color experience the effects of racial capitalism online, particularly with respect to topics of creative ownership and authenticity."
            }
        ]
    }
}

{
    "Target Definition": {
        "Target User Group": "Muslim Americans who are highly visible – e.g.journalists, activists, and aspiring politicians",
        "Tasks": "craft counter-narratives, reclaim control of their stories, and mitigate the harm directed at them",
        "Application scenarios": "engage with broader publics online"
    },
    "Artifact Knowledge": {
        "Knowledge type": [
            "Interaction techniques",
            "Design"
        ],
        "Supporting knowledge": "Subaltern counterpublics, Habermasian public sphere, Restorative justice",
        "Contributions": [
            {
                "Innovation type": "Design",
                "Supporting knowledge": "Subaltern counterpublics",
                "Function": "protect people from harm",
                "Embedded knowledge": {
                    "Prototype, script or models": "1. Community building, education, and making values, rules, and accountability mechanisms visible. 2. Platforms prioritize maximum engagement and broad content distribution over other values such as user safety.",
                    "Material or crafts": "Platform affordances and its alternatives"
                },
                "Implementation": "1. Graduated privileges for interacting with other users, particularly ones who the user is not well connected to. 2. ‘Bunker’ mode for social media accounts that limits user accessibility from harm but provides information and social support they need to protect themselves."
            },
            {
                "Innovation type": "Interaction techniques",
                "Supporting knowledge": "Restorative justice",
                "Function": "protect people from harm",
                "Embedded knowledge": {
                    "Input or control techniques": "Graduated privileges for interacting with other users",
                    "Output or feedback methods": "Social support for the victims"
                },
                "Implementation": "New affordances and their safety mechanisms."
            }
        ]
    },
    "Results": {
        "Performance": "Sustained harm over time and space limits the external function of online counterpublics for American Muslims. ",
        "User feedback": "Platforms are perceived as failing to protect them and failing to provide adequate support, feedback, reporting systems. "
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Content moderation’s impact on people of marginalized identities is to either conform to dominant norms or to resist. ",
                "This study": "Design and implementation of social media platforms for people from marginalized groups such as Muslim Americans"
            },
            {
                "Previous studies": "Individual content pieces and mass reporting content can still fail to prevent and stop the harm that the target people have faced",
                "This study": "Social media platforms prioritize maximum engagement and broad content distribution over other values such as user safety."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Sustained harm over time and space limits the external function of online counterpublics for American Muslims",
                "Result": "Sustained harm over time and space limits the external function of online counterpublics for American Muslims. "
            },
            {
                "Innovation": "The social media platforms’ safety measures have been inadequate to support marginalized people.",
                "Result": "Platforms are perceived as failing to protect them and failing to provide adequate support, feedback, reporting systems."
            }
        ]
    }
}

{
    "Target Definition": {
        "Target User Group": "US digital news consumers",
        "Tasks": "assessing the authenticity and trustworthiness of available digital news sources",
        "Application scenarios": "online news consumption"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "uses and gratification (U&G) framework",
            "Function": "authenticate digital news content",
            "Embedded knowledge": {
                "Architecture or framework": "cryptographic provenance system",
                "Tool or tool kits": "news authentication tool"
            },
            "Implementation": "Python, pastecs, psych, ggplot2"
        }
    ],
    "Results": {
        "Performance": "participants indicated that the proposed features of a cryptographic provenance system would increase their trust in online news",
        "User feedback": "participants reported specific needs and expectations for a usable news authentication tool, including the ability to authenticate article provenance and embedded material, identify equivocation, and create a record of changes"
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "previous work focused on fact-checking and fake news identification",
                "This study": "this study proposes a cryptographic provenance system for digital news authentication"
            }
        ],
        "Quadruple": [
            {
                "Innovation": "cryptographic provenance system for digital news authentication",
                "Result": "participants indicated that the proposed features of a cryptographic provenance system would increase their trust in online news"
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Users who have to make quick decisions while retweeting online content",
        "Tasks": "Deciding whether to retweet a piece of information online",
        "Application scenarios": "Online platforms, retweeting scenarios, and social media"
    },
    "Contributions": [
        {
            "Innovation type": "Design",
            "Supporting knowledge": "AMPS framework",
            "Function": "To support users in their credibility assessment of a tweet",
            "Embedded knowledge": {
                "Prototype, script or models": "Tweet trajectories and contextual cues based on the AMPS framework",
                "Material or crafts": "Designing a retweeting interface with trajectory and cue cards"
            },
            "Implementation": "Implementing the trajectory and cue cards within the retweeting interface"
        }
    ],
    "Results": {
        "Performance": "Participants employed the AMPS-based cues to assess credibility of an account based on its authenticity, online associations, and contentious behavior. Participants used the trajectory to evaluate their trust towards information spreaders and assess the consequences of sharing information. Participants became more critical of their online feed and were able to discern problematic content. Participants became more careful about what they shared online and questioned their trust towards information spreaders. The proposed intervention helped participants re-evaluate their knowledge-based trust in their network and made them question one’s trust towards information spreaders and thus curtail the spread of misinformation.",
        "User feedback": "Participants found the intervention useful for credibility assessment and expressed the need for cues that signal account’s evolving behavior. Participants wanted an easy access to online information trajectory and found the trajectory-based intervention to be useful for exposing the role of institutional credibility obscured by the current design of social media."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Prior research on social signals and platform design for tackling misinformation",
                "This study": "The AMPS framework and tweet trajectories for supporting media literacy"
            },
            {
                "Previous studies": "Prior research on diffusion-based metrics for assessing credibility",
                "This study": "The concept of tweet trajectories for illustrating the spread of information"
            }
        ],
        "Quadruple": [
            {
                "Innovation": "The AMPS framework and tweet trajectories for supporting media literacy",
                "Result": "Participants employed the AMPS-based cues to assess credibility of an account based on its authenticity, online associations, and contentious behavior. Participants used the trajectory to evaluate their trust towards information spreaders and assess the consequences of sharing information."
            },
            {
                "Innovation": "The concept of tweet trajectories for illustrating the spread of information",
                "Result": "Participants became more critical of their online feed and were able to discern problematic content. Participants became more careful about what they shared online and questioned their trust towards information spreaders."
            }
        ]
    }
}

{
    "Target Definition": {
        "Target User Group": "Data subjects in the workplace",
        "Tasks": "Interacting with Emotion AI systems",
        "Application scenarios": "Workplace settings where Emotion AI is used for various purposes such as employee wellbeing, performance management, and workplace safety"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Relational ethics lens",
            "Function": "Improve employee wellbeing and reduce bias in the workplace",
            "Embedded knowledge": {
                "Architecture or framework": "Emotion AI system that uses facial expressions and speech patterns to detect emotions",
                "Tool or tool kits": "None mentioned"
            },
            "Implementation": "Not specified"
        }
    ],
    "Results": {
        "Performance": "The study found that data subjects in the workplace have concerns about the use of Emotion AI, including potential biases and inaccuracies, and that these concerns can lead to negative impacts on their wellbeing and job performance",
        "User feedback": "Data subjects expressed concerns about the use of Emotion AI in the workplace, including concerns about bias, accuracy, and the potential for negative impacts on their wellbeing and job performance"
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Emotion AI systems have been developed for various applications, but their use in the workplace has not been extensively studied",
                "This study": "This study uses a relational ethics lens to examine the use of Emotion AI in the workplace and its potential impacts on data subjects"
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Use of Emotion AI in the workplace",
                "Result": "Data subjects have concerns about bias, accuracy, and negative impacts on wellbeing and job performance"
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Decision makers and decision subjects in the context of university admissions",
        "Tasks": "Identifying ways to improve decision-making practices",
        "Application scenarios": "University admissions review process"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Participatory AI design, reflection, and deliberation",
            "Function": "Support stakeholders in identifying ways to improve their decision practice by building an ML model with historic data",
            "Embedded knowledge": {
                "Architecture or framework": "Deliberating with AI web tool",
                "Tool or tool kits": "None"
            },
            "Implementation": "React and Material-UI on the frontend, and Flask and MongoDB in the backend"
        }
    ],
    "Results": {
        "Performance": "Participants were able to generate ideas for future decision-making and identify patterns of past decision-making",
        "User feedback": "Participants found the tool helpful in identifying biases and potential harms in historical data"
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Automated decision-making systems",
                "This study": "Using machine learning to improve human decision-making"
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Deliberating with AI web tool",
                "Result": "Participants were able to generate ideas for future decision-making and identify patterns of past decision-making"
            }
        ]
    }
}

{
    "Target Definition": {
        "Target User Group": "Youth (Instagram users between the ages of 13 and 21)",
        "Tasks": "Detecting safe and unsafe conversations",
        "Application scenarios": "Instagram direct messages"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "HCI principles and machine learning algorithms",
            "Function": "Detecting safe and unsafe conversations",
            "Embedded knowledge": {
                "Architecture or framework": "A multimodal approach combining metadata, linguistic cues, and image features",
                "Tool or tool kits": "A machine learning framework for detecting safe and unsafe conversations"
            },
            "Implementation": "Metadata--Instagram API; Linguistic cues--Convolutional Neural Network (CNN); Image features--Optical Character Recognition (OCR) tool Pytesseract and MSCOCO deep learning model"
        }
    ],
    "Results": {
        "Performance": "Accuracy of 0.83 for weighted-vote ensemble classifier; Recall rate of 0.74; Precision rate of 0.75; F1 score of 0.74",
        "User feedback": "Improved performance over individual classifiers; Limited by the quality of the training data; Potential for overfitting"
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Focused on public posts and images for analysis; Relied on third-party annotators; Focused on one type of risk rather than looking at risks more holistically",
                "This study": "Collected private Instagram conversations from 172 youth; Utilized a multimodal approach for risk detection using three different feature sets (metadata, linguistic cues, and image features); Combined predictions using a weighted-vote ensemble classifier"
            }
        ],
        "Quadruple": [
            {
                "Innovation": "A multimodal approach combining metadata, linguistic cues, and image features",
                "Result": "Improved performance over individual classifiers; Limited by the quality of the training data; Potential for overfitting"
            },
            {
                "Innovation": "A machine learning framework for detecting safe and unsafe conversations",
                "Result": "Accuracy of 0.83 for weighted-vote ensemble classifier; Recall rate of 0.74; Precision rate of 0.75; F1 score of 0.74"
            }
        ]
    }
}

{
    "Target Definition": {
        "Target User Group": "Social media users",
        "Tasks": "Interaction with social media platforms",
        "Application Scenarios": "Social media platforms and their algorithms"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Fairness definitions",
            "Function": "Enable public oversight into how social media platforms affect individuals and society",
            "Embedded knowledge": {
                "Architecture or framework": "Platform-supported auditing framework",
                "Tool or tool kits": "None"
            },
            "Implementation": "Protected relevance estimators using the Laplace Mechanism"
        }
    ],
    "Results": {
        "Performance": "Increases required sample size by only approximately a factor of 4 for reasonable auditing parameters",
        "User feedback": "Auditors can verify fairness of algorithms without compromising user privacy"
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Lack of transparency in relevance estimators",
                "This study": "Enumerates challenges of existing methods and proposes a platform-supported auditing framework"
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Platform-supported auditing framework",
                "Result": "Increases required sample size by only approximately a factor of 4 for reasonable auditing parameters"
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "People working with AI systems",
        "Tasks": "Improving decision making",
        "Application scenarios": "Tasks ranging from diagnosing prostate cancer to screening calls to child welfare hotlines"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Mental models, Don Norman’s mental model framework",
            "Function": "Help people appropriately rely on AI aids",
            "Embedded knowledge": {
                "Architecture or framework": "Providing behavior descriptions of an AI’s performance for subgroups of instances",
                "Tool or tool kits": "Used a wizard-of-oz AI system, mock AI outputs"
            },
            "Implementation": "Wizard-of-oz AI system--Python"
        }
    ],
    "Results": {
        "Performance": "Behavior descriptions can significantly improve human-AI team performance by helping people both correct AI failures and rely on the AI when it is more accurate",
        "User feedback": "No significant differences in user’s perception of the AI when they were given behavior descriptions"
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Did not provide behavior descriptions of AI performance for subgroups of instances",
                "This study": "Provided behavior descriptions of AI performance for subgroups of instances"
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Providing behavior descriptions of AI performance for subgroups of instances",
                "Result": "Significantly improved human-AI team performance"
            }
        ]
    }
}

{
    "Target Definition": {
        "Target User Group": "Students and MTurk workers who collaborate with others on crowdwork platforms or in the workplace",
        "Tasks": "Peer evaluations",
        "Application scenarios": "Educational and work settings"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Activity traces",
            "Function": "Improve peer evaluations",
            "Embedded knowledge": {
                "Architecture or framework": "None",
                "Tool or tool kits": "None"
            },
            "Implementation": "None"
        }
    ],
    "Results": {
        "Performance": "The study found that reviewing activity traces led to a significant decrease in the standard deviation of evaluation scores, indicating increased consistency among evaluators. The study also found that reviewing activity traces significantly increased the magnitude of revisions that participants made to their initial evaluations.",
        "User feedback": "Participants in the treatment condition perceived the evaluation scores they received as being more accurate and were more likely to agree with the statement that the evaluations they received accurately represented their contributions."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Previous studies have explored the use of activity traces to support awareness and coordination in teams, but few have examined the impact of using activity traces on peer evaluations.",
                "This study": "This study investigates the effects of using activity traces on peer evaluations and finds that reviewing activity traces can improve the consistency and perceived accuracy of peer evaluations."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Using activity traces to support peer evaluations",
                "Result": "Improved consistency and perceived accuracy of peer evaluations"
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Human decision-makers working with AI models",
        "Tasks": "Making predictions and decision-making in various contexts using AI-assisted tools",
        "Application scenarios": "Child welfare, healthcare, education, real estate"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "human-AI complementarity, machine learning",
            "Function": "To help human decision-makers more effectively integrate AI capabilities with their own expertise",
            "Embedded knowledge": {
                "Architecture or framework": "Machine learning model with linear regression, Prompt-based system to encourage reflection on complementary abilities between humans and AI models",
                "Tool or tool kits": "Pre-trained model for predictive tasks, Interface prompts for unobservables",
                "Implementation": "Ames, Iowa Housing Dataset for house price prediction task"
            }
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Human-computer interaction, machine learning",
            "Function": "To change how humans integrate model outputs and unobservables when making predictions",
            "Embedded knowledge": {
                "Input or control techniques": "Reflective prompts for humans to integrate unobservables, real-time prompts during the training and testing phases",
                "Output or feedback methods": "Model predictions and unobservables",
                "Implementation": "Platforms for predictive tasks such as house price prediction"
            }
        }
    ],
    "Results": {
        "Performance": "The study found that presenting prompts about unobservables can change how humans integrate model outputs and unobservables when making predictions, and this shift is driven by a change in how participants with higher prior experience use the information presented to them. The study also found that the impacts of these prompts can vary depending on decision-makers’ prior domain expertise. Participants who were shown in-the-moment prompts were more likely to make predictions based on a combination of model predictions and their own judgments.",
        "User feedback": "The study did not collect direct user feedback on the system or the interaction techniques."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Provided human-AI complementarity without exploring how humans integrate unobservables in their decision-making process",
                "This study": "Proposed an interface prompt to encourage humans to reflect on unobservables, allowing humans to better integrate unobservables and AI model predictions in their decision-making process"
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Reflective prompts for humans to integrate unobservables in predictive tasks",
                "Result": "Participants with higher prior experience integrated model outputs and unobservables better, but continuous prompting about unobservables did not translate to improved predictive performance."
            }
        ]
    }
}

{
    "Target Definition": {
        "Target User Group": "Users in Federated Learning for Human Activity Recognition",
        "Tasks": "Improving the accuracy, fairness, and robustness of the FL model simultaneously for the HAR problem",
        "Application scenarios": "Federated Learning scenarios with heterogeneous data among users"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Hierarchical clustering-based method",
            "Function": "Robust and fair Human Activity Recognition",
            "Embedded knowledge": {
                "Architecture or framework": "FedCHAR and FedCHAR-DC",
                "Tool or toolkits": ""
            },
            "Implementation": "Federated Learning, Hierarchical Clustering, TensorFlow, 2 NVIDIA 3080TI GPUS, 56-core CPU"
        },
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "",
            "Function": "Isolating benign nodes from malicious nodes through clustering",
            "Embedded knowledge": {
                "Input or control techniques": "Uploading model updates to the server after the user calculates the model update parameters",
                "Output or feedback methods": ""
            },
            "Implementation": "FedCHAR and FedCHAR-DC"
        }
    ],
    "Results": {
        "Performance": "FedCHAR outperforms other baselines by at least about 4% and at most by about 16% in the benign scenario. In attack scenarios, FedCHAR outperforms other baselines by at least about 7%, 4%, 6%, and 15%, and at most about 67%, 15%, 60%, and 60% over the four attack types, respectively.",
        "User feedback": "FedCHAR maintains the fairness of the model performance among all benign users while ensuring that the performance of the vast majority of user models is protected from attacks."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Most existing FL frameworks aim to solve specific problems while ignoring other properties",
                "This study": "FedCHAR breaks the constraints between the properties mentioned above (e.g., robustness and fairness), which not only improves the accuracy and the fairness of model performance by exploring intrinsically similar relationships among users in the benign scenario but also improves the robustness of the system by identifying malicious nodes through clustering"
            }
        ],
        "Quadruple": [
            {
                "Innovation": "FedCHAR breaks the constraints between the properties mentioned above (e.g., robustness and fairness), which not only improves the accuracy and the fairness of model performance by exploring intrinsically similar relationships among users in the benign scenario but also improves the robustness of the system by identifying malicious nodes through clustering",
                "Result": "FedCHAR outperforms other baselines by at least about 4% and at most by about 16% in the benign scenario. In attack scenarios, FedCHAR outperforms other baselines by at least about 7%, 4%, 6%, and 15%, and at most about 67%, 15%, 60%, and 60% over the four attack types, respectively."
            }
        ]
    }
}

{
    "Target Definition": {
        "Target User Group": "people with mental health challenges, specifically those with Bipolar Disorder (BD)",
        "Tasks": "managing their mental health conditions, including gaining support from online communities, seeking advice, and balancing daily life with episodes",
        "Application scenarios": "online forums, social media platforms, and other digital technologies"
    },
    "Contributions": [
        {
            "Innovation type": "Interaction techniques",
            "Supporting knowledge": "Lived informatics, personal social media ecosystems",
            "Function": "facilitate online support, self-tracking, and community building for people with BD",
            "Embedded knowledge": {
                "Input or control techniques": "using social media, online forums, and other digital technologies to seek support and share experiences",
                "Output or feedback methods": "using self-tracking applications and mood charts to gain insights and monitor conditions"
            },
            "Implementation": "using platforms such as Reddit, Facebook, and Instagram"
        },
        {
            "Innovation type": "Design",
            "Supporting knowledge": "Collaborative and social computing, Empirical studies in HCI, HCI design and evaluation methods",
            "Function": "design technologies that support people with BD in managing their mental health conditions",
            "Embedded knowledge": {
                "Prototype, script or models": "designing self-tracking applications, online communities, and other digital tools that cater to the needs of people with BD"
            },
            "Implementation": "using design parameters such as anonymity, accessibility, and user-centered design"
        }
    ],
    "Results": {
        "Performance": "the study found that people with BD use a variety of technologies to manage their mental health conditions, including social media, online forums, and self-tracking applications",
        "User feedback": "participants reported positive experiences with online communities and self-tracking applications, but also expressed concerns about anonymity and the quality of help"
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "previous studies focused on specific technologies or platforms, but did not provide a comprehensive understanding of the technology ecosystem used by people with BD",
                "This study": "this study provides a comprehensive understanding of the technology ecosystem used by people with BD, including the roles of different technologies and their effects on mental health management"
            },
            {
                "Previous studies": "previous studies did not examine the nuances of information-seeking behaviors in online communities",
                "This study": "this study examines the nuances of information-seeking behaviors in online communities and how to better support such behaviors in the context of mental illnesses"
            }
        ],
        "Quadruple": [
            {
                "Innovation": "designing self-tracking applications that cater to the needs of people with BD",
                "Result": "participants reported positive experiences with self-tracking applications, but also expressed concerns about anonymity and the quality of help"
            },
            {
                "Innovation": "designing online communities that provide support and resources for people with BD",
                "Result": "participants reported positive experiences with online communities, but also expressed concerns about the quality of help and the potential for misinformation"
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Twitter users affected by state-sponsored information operations (SSIOs)",
        "Tasks": "Analyzing and understanding the behavior of SSIOs on Twitter",
        "Application scenarios": "Twitter platform"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Cooperative work and social roles framework",
            "Function": "Analyze and understand the behavior of SSIOs on Twitter",
            "Embedded knowledge": {
                "Architecture or framework": "Bag-of-words (BOW) model for clustering and describing user activity traces",
                "Tool or tool kits": "Twitter Information Operations archive and baseline dataset of genuine Twitter users"
            },
            "Implementation": "Python programming language and libraries such as scikit-learn and pandas"
        }
    ],
    "Results": {
        "Performance": "The study found that SSIOs violate the core assumption of the social bot framework and exhibit a division of labor, with different clusters of agents serving different roles. The study also found that existing social bot detection techniques are biased towards detecting specific levels of coordination and complexity.",
        "User feedback": "Not applicable, as the study focuses on analyzing SSIO behavior rather than collecting user feedback."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Social bot framework",
                "This study": "Cooperative work and social roles framework for understanding SSIOs"
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Bag-of-words (BOW) model for clustering and describing user activity traces",
                "Result": "Effective in identifying behavioral patterns and roles of SSIO agents"
            },
            {
                "Innovation": "Cooperative work and social roles framework",
                "Result": "Provides a more comprehensive understanding of SSIO behavior and division of labor"
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "People dealing with end of life contexts, including the dying and bereaved.",
        "Tasks": "Passing down digital legacy materials, including values, wishes, identities, objects, digital content, heirlooms, or other meaningful items.",
        "Application scenarios": "End of life contexts, including death of a loved one, inheritance, and memorialization."
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Information lifecycles, social computing, and human-centered design.",
            "Function": "Support the passing down of digital legacy materials between individuals.",
            "Embedded knowledge": {
                "Architecture or framework": "A digital legacy data lifecycle model that includes encoding, accessing, and dispossessing stages.",
                "Tool or tool kits": "None mentioned."
            },
            "Implementation": "None mentioned."
        }
    ],
    "Results": {
        "Performance": "The study provides a comprehensive review of digital legacy research and identifies gaps in current research, but does not provide concrete statistical descriptions of performance.",
        "User feedback": "The study does not provide user feedback, but rather presents a synthesis of existing research on digital legacy."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Previous research has focused on specific aspects of digital legacy, such as inheritance policies or platform functionality.",
                "This study": "This study provides a comprehensive review of digital legacy research and identifies gaps in current research, highlighting the need for a more holistic approach to digital legacy management."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "A digital legacy data lifecycle model that includes encoding, accessing, and dispossessing stages.",
                "Result": "The study provides a comprehensive review of digital legacy research and identifies gaps in current research."
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "Blind and low-vision (BLV) individuals",
        "Tasks": "Interactions between BLV individuals and guide dogs or robots",
        "Application scenarios": "Navigation assistance in daily life"
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "User-centered design principles",
            "Function": "Provide navigation assistance to BLV individuals",
            "Embedded knowledge": {
                "Architecture or framework": "Quadruped robot design",
                "Tool or tool kits": "Sensor suite and perceptual intelligence"
            },
            "Implementation": "Unitree Robotics--Quadruped robot; Python--Sensor suite and perceptual intelligence"
        }
    ],
    "Results": {
        "Performance": "The study reveals limitations in handler-guide dog interactions and provides insights for guide dog robot design",
        "User feedback": "BLV individuals and guide dog handlers express enthusiasm for the concept of a guide dog robot and highlight the importance of trust and personalization"
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Limited attention to user needs and requirements in guide dog robot development",
                "This study": "User-centered design approach to inform guide dog robot development"
            }
        ],
        "Quadruple": [
            {
                "Innovation": "User-centered design approach",
                "Result": "Insights for guide dog robot design and user enthusiasm for the concept"
            }
        ]
    }
}
{
    "Target Definition": {
        "Target User Group": "users of voice assistants",
        "Tasks": "cooking tasks that require temporal and spatial synchronization between objects and the task at hand",
        "Application scenarios": "Cooking tasks at home, in which voice assistants guide the users in complex multi-stage and context-dependent tasks."
    },
    "Contributions": [
        {
            "Innovation type": "System",
            "Supporting knowledge": "Conversational design",
            "Function": "Conversational Agents to help users to support people in complex tasks, through conversation and guiding information, support information on object interactions with speech output that makes these requests seem task-synchronized with less requirement of reinitializing this action upon different information inquiry’s results with agent use on multitasking such as hands free input for task when eyes are busy such as in stove",
            "Embedded knowledge": {
                "Architecture or framework": "Developing shared vocabulary within the bounds of the recipe interaction, drawing directly from the textual description of the recipe to check the instructions items for all step lists, recipes instructions, providing control mechanisms in the tool tips and step completion from wizard interface for VA. "
            },
            "Implementation": "Wizard-of-Oz method wizard controlled with physical smart speaker running the open-source Mycroft.ai conversational agent software and Google’s text-to-speech service, Camera for wizards control the conversation on video output to display the task, sound for VA to produce utterances "
        }
    ],
    "Results": {
        "Performance": "The study found that interactions with the context-aware voice agent resulted in more fluent and less constrained interaction and increased complexity of requests when navigating through the recipe steps with a number of additional tools such as timers.",
        "User feedback": "Results showed an improved division of labor from the point of view of conversational management between the device, the control of the device, and user with each conversational turn."
    },
    "Second Extraction": {
        "Innovations": [
            {
                "Previous studies": "Developments in speech technology only partially consider context which operates as reactive conversation.",
                "This study": "Imbues VAs with contextual awareness to support conversational interaction using the context and objects involved during the interaction, including voice agent to comprehend objects during the tasks at hand and provide timely relevant responses."
            },
            {
                "Previous studies": "Participants use simple terms and short syntactic structures and keyword-like utterances and often experience communicative failure when interacting with VAs.",
                "This study": "The addition of context awareness improved users’ interaction, resulting in reduced conversational effort required to get the required information when error arose."
            }
        ],
        "Quadruple": [
            {
                "Innovation": "Imbues VAs with contextual awareness to support conversational interaction using the context and objects involved during the interaction.",
                "Result": "Increased fluency, and linguistic complexity and reliance on the shared context during conversations between humans and agent when grounded mutual understanding over steps needed of sequential dialogue processing task contexts on error due results was apparent but mitigated more robust inter dependence ."
            },
            {
                "Innovation": "Use context and objects during interaction.",
                "Result": "Improve results were evident to grounding their reliance understanding use explicit progress was results turn up success is ground control can all given rely what help found due them further these work an some extent provide during rely no were out common tool query terms set off follow may perform seen perform example evidence we provided due full  so through provided each tasks most will just if make are well design dialogue still good has out study current device human shown studies help up many form information object both new seen VA if follow see get control now way query way way our be each users show voice it device like during at there step further both further interaction system tasks them could need terms shown make  there even work better such step result one off off. More seen steps information how how tasks study they at by. Study less during form make from well perform what perform or shown but new with such were interaction need what follow was tasks is seen follow help through these these system good user object just results by are voice now information voice ground show are result when for  current make one were such of design most has studies have tasks also."
            }
        ]
    }
}